This file is a merged representation of the entire codebase, combined into a single document by Repomix.

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded

Additional Info:
----------------

================================================================
Directory Structure
================================================================
argus_track/
  analysis/
    static_analyser.py
  core/
    __init__.py
    detection.py
    gps.py
    track.py
  detectors/
    __init__.py
    base.py
    mock.py
    yolo.py
  filters/
    __init__.py
    kalman.py
  trackers/
    __init__.py
    bytetrack.py
    lightpost_tracker.py
  utils/
    __init__.py
    config_validator.py
    gps_utils.py
    io.py
    iou.py
    visualization.py
  __init__.py
  __version__.py
  config.py
  exceptions.py
  main.py
  requirements.txt
docs/
  HOW_IT_WORKS.md
  library_doc.md
  USAGE_GUIDE.md
examples/
  config_examples/
    default_config.yaml
  basic_tracking.py
  geolocation_tracking.py
  video_tracking_with_gps.py
images/
  bytetrack-workflow-diagram.svg
tests/
  aditional_comprehensive.py
  conftest.py
  test_core.py
  test_detector.py
  test_integration.py
.gitignore
LICENSE
README.md
setup.py

================================================================
Files
================================================================

================
File: argus_track/analysis/static_analyser.py
================
"""Enhanced static object analysis"""

import numpy as np
from typing import Dict, List, Tuple, Optional
from sklearn.cluster import DBSCAN

from ..core import Track, Detection


class StaticObjectAnalyzer:
    """Advanced analysis of static objects in tracking data"""
    
    def __init__(self, 
                 position_threshold: float = 2.0,
                 velocity_threshold: float = 0.5,
                 min_observations: int = 10,
                 stability_window: int = 30):
        """
        Initialize static object analyzer
        
        Args:
            position_threshold: Maximum position variance for static classification
            velocity_threshold: Maximum velocity for static classification
            min_observations: Minimum observations required
            stability_window: Window size for stability analysis
        """
        self.position_threshold = position_threshold
        self.velocity_threshold = velocity_threshold
        self.min_observations = min_observations
        self.stability_window = stability_window
    
    def analyze_track(self, track: Track) -> Dict[str, float]:
        """
        Analyze a single track for static behavior
        
        Args:
            track: Track to analyze
            
        Returns:
            Dictionary with analysis metrics
        """
        if len(track.detections) < self.min_observations:
            return {
                'is_static': False,
                'confidence': 0.0,
                'position_variance': float('inf'),
                'velocity_mean': float('inf'),
                'stability_score': 0.0
            }
        
        # Extract positions
        positions = np.array([det.center for det in track.detections])
        
        # Calculate position variance
        position_variance = np.std(positions, axis=0).mean()
        
        # Calculate velocities
        if len(positions) > 1:
            velocities = np.diff(positions, axis=0)
            velocity_mean = np.abs(velocities).mean()
        else:
            velocity_mean = 0.0
        
        # Calculate stability score using sliding window
        stability_scores = []
        for i in range(len(positions) - self.stability_window + 1):
            window = positions[i:i + self.stability_window]
            window_variance = np.std(window, axis=0).mean()
            stability_scores.append(1.0 / (1.0 + window_variance))
        
        stability_score = np.mean(stability_scores) if stability_scores else 0.0
        
        # Determine if static
        is_static = (
            position_variance < self.position_threshold and
            velocity_mean < self.velocity_threshold
        )
        
        # Calculate confidence
        confidence = min(1.0, stability_score * (1.0 - velocity_mean / self.velocity_threshold))
        
        return {
            'is_static': is_static,
            'confidence': confidence,
            'position_variance': position_variance,
            'velocity_mean': velocity_mean,
            'stability_score': stability_score
        }
    
    def find_clusters(self, tracks: Dict[int, Track], 
                     eps: float = 50.0, 
                     min_samples: int = 2) -> Dict[int, int]:
        """
        Find clusters of static objects
        
        Args:
            tracks: Dictionary of tracks
            eps: Maximum distance between points in a cluster
            min_samples: Minimum samples in a cluster
            
        Returns:
            Dictionary mapping track_id to cluster_id
        """
        # Filter static tracks
        static_tracks = {}
        positions = []
        track_ids = []
        
        for track_id, track in tracks.items():
            analysis = self.analyze_track(track)
            if analysis['is_static']:
                static_tracks[track_id] = track
                positions.append(track.trajectory[-1])  # Use last position
                track_ids.append(track_id)
        
        if len(positions) < min_samples:
            return {}
        
        # Perform clustering
        positions = np.array(positions)
        clustering = DBSCAN(eps=eps, min_samples=min_samples).fit(positions)
        
        # Map track IDs to clusters
        cluster_mapping = {}
        for track_id, cluster_id in zip(track_ids, clustering.labels_):
            if cluster_id != -1:  # Ignore noise points
                cluster_mapping[track_id] = cluster_id
        
        return cluster_mapping
    
    def merge_duplicate_tracks(self, tracks: Dict[int, Track],
                              distance_threshold: float = 30.0) -> Dict[int, List[int]]:
        """
        Identify duplicate tracks of the same static object
        
        Args:
            tracks: Dictionary of tracks
            distance_threshold: Maximum distance to consider duplicates
            
        Returns:
            Dictionary mapping primary track_id to list of duplicate track_ids
        """
        static_tracks = []
        for track_id, track in tracks.items():
            analysis = self.analyze_track(track)
            if analysis['is_static']:
                static_tracks.append((track_id, track))
        
        duplicates = {}
        processed = set()
        
        for i, (track_id1, track1) in enumerate(static_tracks):
            if track_id1 in processed:
                continue
                
            duplicates[track_id1] = []
            
            for j, (track_id2, track2) in enumerate(static_tracks[i+1:], i+1):
                if track_id2 in processed:
                    continue
                
                # Calculate distance between average positions
                pos1 = np.mean([det.center for det in track1.detections], axis=0)
                pos2 = np.mean([det.center for det in track2.detections], axis=0)
                distance = np.linalg.norm(pos1 - pos2)
                
                if distance < distance_threshold:
                    duplicates[track_id1].append(track_id2)
                    processed.add(track_id2)
        
        # Remove entries with no duplicates
        return {k: v for k, v in duplicates.items() if v}
    
    def calculate_persistence_score(self, track: Track, 
                                   total_frames: int) -> float:
        """
        Calculate persistence score for a track
        
        Args:
            track: Track to analyze
            total_frames: Total frames in video
            
        Returns:
            Persistence score between 0 and 1
        """
        if total_frames == 0:
            return 0.0
        
        # Calculate presence ratio
        presence_ratio = track.age / total_frames
        
        # Calculate detection density
        if track.age > 0:
            detection_density = len(track.detections) / track.age
        else:
            detection_density = 0.0
        
        # Combine metrics
        persistence_score = presence_ratio * detection_density
        
        return min(1.0, persistence_score)

================
File: argus_track/core/__init__.py
================
"""Core data structures for ByteTrack Light Post Tracking System"""

from .detection import Detection
from .track import Track
from .gps import GPSData

__all__ = ["Detection", "Track", "GPSData"]

================
File: argus_track/core/detection.py
================
"""Detection data structure"""

from dataclasses import dataclass
import numpy as np


@dataclass
class Detection:
    """Single object detection"""
    bbox: np.ndarray                   # [x1, y1, x2, y2] format
    score: float                       # Confidence score [0, 1]
    class_id: int                      # Object class ID
    frame_id: int                      # Frame number
    
    @property
    def tlbr(self) -> np.ndarray:
        """Get bounding box in top-left, bottom-right format"""
        return self.bbox
    
    @property
    def xywh(self) -> np.ndarray:
        """Get bounding box in center-x, center-y, width, height format"""
        x1, y1, x2, y2 = self.bbox
        return np.array([
            (x1 + x2) / 2,  # center x
            (y1 + y2) / 2,  # center y
            x2 - x1,        # width
            y2 - y1         # height
        ])
    
    @property
    def area(self) -> float:
        """Calculate bounding box area"""
        x1, y1, x2, y2 = self.bbox
        return (x2 - x1) * (y2 - y1)
    
    @property
    def center(self) -> np.ndarray:
        """Get center point of bounding box"""
        x1, y1, x2, y2 = self.bbox
        return np.array([(x1 + x2) / 2, (y1 + y2) / 2])
    
    def to_dict(self) -> dict:
        """Convert to dictionary representation"""
        return {
            'bbox': self.bbox.tolist(),
            'score': self.score,
            'class_id': self.class_id,
            'frame_id': self.frame_id
        }
    
    @classmethod
    def from_dict(cls, data: dict) -> 'Detection':
        """Create from dictionary representation"""
        return cls(
            bbox=np.array(data['bbox']),
            score=data['score'],
            class_id=data['class_id'],
            frame_id=data['frame_id']
        )

================
File: argus_track/core/gps.py
================
"""GPS data structure"""

from dataclasses import dataclass
from typing import Dict, Any


@dataclass
class GPSData:
    """GPS data for a single frame"""
    timestamp: float
    latitude: float
    longitude: float
    altitude: float
    heading: float
    accuracy: float = 1.0              # GPS accuracy in meters
    
    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary representation"""
        return {
            'timestamp': self.timestamp,
            'latitude': self.latitude,
            'longitude': self.longitude,
            'altitude': self.altitude,
            'heading': self.heading,
            'accuracy': self.accuracy
        }
    
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'GPSData':
        """Create from dictionary representation"""
        return cls(**data)
    
    @classmethod
    def from_csv_line(cls, line: str) -> 'GPSData':
        """Create from CSV line"""
        parts = line.strip().split(',')
        if len(parts) < 5:
            raise ValueError(f"Invalid GPS data line: {line}")
        
        return cls(
            timestamp=float(parts[0]),
            latitude=float(parts[1]),
            longitude=float(parts[2]),
            altitude=float(parts[3]),
            heading=float(parts[4]),
            accuracy=float(parts[5]) if len(parts) > 5 else 1.0
        )

================
File: argus_track/core/track.py
================
"""Track data structure"""

from dataclasses import dataclass, field
from typing import List, Optional
import numpy as np

from .detection import Detection


@dataclass
class Track:
    """Represents a tracked object through multiple frames"""
    track_id: int
    detections: List[Detection] = field(default_factory=list)
    kalman_filter: Optional['KalmanBoxTracker'] = None
    state: str = 'tentative'           # tentative, confirmed, lost, removed
    hits: int = 0                      # Number of successful updates
    age: int = 0                       # Total frames since creation
    time_since_update: int = 0         # Frames since last update
    start_frame: int = 0
    
    @property
    def is_confirmed(self) -> bool:
        """Check if track is confirmed (has enough hits)"""
        return self.state == 'confirmed'
    
    @property
    def is_active(self) -> bool:
        """Check if track is currently active"""
        return self.state in ['tentative', 'confirmed']
    
    def to_tlbr(self) -> np.ndarray:
        """Get current position in tlbr format"""
        if self.kalman_filter is None:
            return self.detections[-1].tlbr if self.detections else np.zeros(4)
        return self.kalman_filter.get_state()
    
    @property
    def last_detection(self) -> Optional[Detection]:
        """Get the most recent detection"""
        return self.detections[-1] if self.detections else None
    
    @property
    def trajectory(self) -> List[np.ndarray]:
        """Get trajectory as list of center points"""
        return [det.center for det in self.detections]
    
    def to_dict(self) -> dict:
        """Convert to dictionary representation"""
        return {
            'track_id': self.track_id,
            'state': self.state,
            'hits': self.hits,
            'age': self.age,
            'time_since_update': self.time_since_update,
            'start_frame': self.start_frame,
            'detections': [det.to_dict() for det in self.detections[-10:]]  # Last 10 detections
        }

================
File: argus_track/detectors/__init__.py
================
"""Object detectors for ByteTrack system"""

from .base import ObjectDetector
from .yolo import YOLODetector
from .mock import MockDetector

__all__ = ["ObjectDetector", "YOLODetector", "MockDetector"]

================
File: argus_track/detectors/base.py
================
"""Base detector interface"""

from abc import ABC, abstractmethod
from typing import List, Dict, Any
import numpy as np


class ObjectDetector(ABC):
    """Abstract base class for object detection modules"""
    
    @abstractmethod
    def detect(self, frame: np.ndarray) -> List[Dict[str, Any]]:
        """
        Detect objects in a frame
        
        Args:
            frame: Input image as numpy array
            
        Returns:
            List of detections with keys: bbox, score, class_name, class_id
        """
        pass
    
    @abstractmethod
    def get_class_names(self) -> List[str]:
        """Get list of detectable class names"""
        pass
    
    def set_target_classes(self, target_classes: List[str]) -> None:
        """Set specific classes to detect"""
        self.target_classes = target_classes

================
File: argus_track/detectors/mock.py
================
"""Mock detector for testing"""

import numpy as np
from typing import List, Dict, Any
import random

from .base import ObjectDetector


class MockDetector(ObjectDetector):
    """Mock detector for testing purposes"""
    
    def __init__(self, target_classes: List[str] = None):
        """
        Initialize mock detector
        
        Args:
            target_classes: List of class names to detect
        """
        self.class_names = [
            'light_post', 'street_light', 'pole', 
            'traffic_light', 'stop_sign', 'person'
        ]
        self.target_classes = target_classes or self.class_names
        self.frame_count = 0
    
    def detect(self, frame: np.ndarray) -> List[Dict[str, Any]]:
        """
        Generate mock detections for testing
        
        Args:
            frame: Input image
            
        Returns:
            List of mock detections
        """
        h, w = frame.shape[:2]
        detections = []
        
        # Generate stable mock detections with slight variations
        base_positions = [
            (100, 100, 150, 300),
            (400, 120, 450, 320),
            (700, 90, 750, 290)
        ]
        
        for i, (x1, y1, x2, y2) in enumerate(base_positions):
            # Add some noise to make it more realistic
            noise = 5 * np.sin(self.frame_count * 0.1 + i)
            
            x1 += int(noise)
            y1 += int(noise * 0.5)
            x2 += int(noise)
            y2 += int(noise * 0.5)
            
            # Ensure bounds
            x1 = max(0, min(x1, w))
            x2 = max(0, min(x2, w))
            y1 = max(0, min(y1, h))
            y2 = max(0, min(y2, h))
            
            # Random class from target classes
            class_name = random.choice(self.target_classes)
            class_id = self.class_names.index(class_name) if class_name in self.class_names else 0
            
            detections.append({
                'bbox': [x1, y1, x2, y2],
                'score': 0.85 + random.uniform(-0.1, 0.1),
                'class_name': class_name,
                'class_id': class_id
            })
        
        self.frame_count += 1
        return detections
    
    def get_class_names(self) -> List[str]:
        """Get list of detectable class names"""
        return self.class_names.copy()

================
File: argus_track/detectors/yolo.py
================
"""YOLO detector implementation"""

import cv2
import numpy as np
from typing import List, Dict, Any, Optional
import logging
from pathlib import Path

from .base import ObjectDetector


class YOLODetector(ObjectDetector):
    """YOLO-based object detector implementation"""
    
    def __init__(self, model_path: str, config_path: str, 
                 target_classes: Optional[List[str]] = None,
                 confidence_threshold: float = 0.5,
                 nms_threshold: float = 0.4):
        """
        Initialize YOLO detector
        
        Args:
            model_path: Path to YOLO weights
            config_path: Path to YOLO config
            target_classes: List of class names to detect (None for all)
            confidence_threshold: Minimum confidence for detections
            nms_threshold: Non-maximum suppression threshold
        """
        self.logger = logging.getLogger(f"{__name__}.YOLODetector")
        self.confidence_threshold = confidence_threshold
        self.nms_threshold = nms_threshold
        
        try:
            # Initialize YOLO model (using OpenCV's DNN module)
            self.net = cv2.dnn.readNet(model_path, config_path)
            
            # Set backend preference (CUDA if available)
            self.net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)
            self.net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)
            
            # Get output layer names
            layer_names = self.net.getLayerNames()
            self.output_layers = [layer_names[i - 1] 
                                for i in self.net.getUnconnectedOutLayers()]
            
            # Load class names
            names_path = Path(config_path).with_suffix('.names')
            if names_path.exists():
                with open(names_path, 'r') as f:
                    self.class_names = [line.strip() for line in f.readlines()]
            else:
                self.logger.warning(f"Class names file not found: {names_path}")
                self.class_names = [f"class_{i}" for i in range(80)]  # Default COCO classes
            
            self.target_classes = target_classes or self.class_names
            self.logger.info(f"Initialized YOLO detector with {len(self.class_names)} classes")
            
        except Exception as e:
            self.logger.error(f"Failed to initialize YOLO detector: {e}")
            raise
    
    def detect(self, frame: np.ndarray) -> List[Dict[str, Any]]:
        """
        Detect objects in frame using YOLO
        
        Args:
            frame: Input image
            
        Returns:
            List of detections
        """
        height, width = frame.shape[:2]
        
        # Prepare input
        blob = cv2.dnn.blobFromImage(frame, 0.00392, (416, 416), (0, 0, 0), 
                                   True, crop=False)
        self.net.setInput(blob)
        
        # Run inference
        outputs = self.net.forward(self.output_layers)
        
        # Extract detections
        boxes = []
        confidences = []
        class_ids = []
        
        for output in outputs:
            for detection in output:
                scores = detection[5:]
                class_id = np.argmax(scores)
                confidence = scores[class_id]
                
                # Filter by confidence and target classes
                class_name = self.class_names[class_id]
                if confidence > self.confidence_threshold and class_name in self.target_classes:
                    # Convert YOLO format to pixel coordinates
                    center_x = int(detection[0] * width)
                    center_y = int(detection[1] * height)
                    w = int(detection[2] * width)
                    h = int(detection[3] * height)
                    
                    # Calculate bounding box
                    x = int(center_x - w / 2)
                    y = int(center_y - h / 2)
                    
                    boxes.append([x, y, w, h])
                    confidences.append(float(confidence))
                    class_ids.append(class_id)
        
        # Apply non-maximum suppression
        indexes = cv2.dnn.NMSBoxes(boxes, confidences, 
                                  self.confidence_threshold, 
                                  self.nms_threshold)
        
        # Format results
        detections = []
        if len(indexes) > 0:
            for i in indexes.flatten():
                x, y, w, h = boxes[i]
                detections.append({
                    'bbox': [x, y, x + w, y + h],  # Convert to tlbr format
                    'score': confidences[i],
                    'class_name': self.class_names[class_ids[i]],
                    'class_id': class_ids[i]
                })
        
        return detections
    
    def get_class_names(self) -> List[str]:
        """Get list of detectable class names"""
        return self.class_names.copy()
    
    def set_backend(self, backend: str = 'cpu') -> None:
        """
        Set computation backend
        
        Args:
            backend: 'cpu', 'cuda', or 'opencl'
        """
        if backend.lower() == 'cuda':
            self.net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)
            self.net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)
        elif backend.lower() == 'opencl':
            self.net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)
            self.net.setPreferableTarget(cv2.dnn.DNN_TARGET_OPENCL)
        else:
            self.net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)
            self.net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)
        
        self.logger.info(f"Set backend to: {backend}")

================
File: argus_track/filters/__init__.py
================
"""Motion filters for tracking"""

from .kalman import KalmanBoxTracker

__all__ = ["KalmanBoxTracker"]

================
File: argus_track/filters/kalman.py
================
# argus_track/filters/kalman.py

"""Kalman filter implementation for object tracking"""

import numpy as np
from filterpy.kalman import KalmanFilter
from typing import List, Optional

from ..core import Detection


class KalmanBoxTracker:
    """
    Kalman filter implementation optimized for static/slow-moving objects
    
    State vector: [x, y, w, h, vx, vy, vw, vh]
    where (x, y) is center position, (w, h) is width/height,
    and v* are the corresponding velocities
    """
    
    def __init__(self, initial_detection: Detection):
        """
        Initialize Kalman filter with detection
        
        Args:
            initial_detection: First detection to initialize the filter
        """
        # 8-dimensional state, 4-dimensional measurement
        self.kf = KalmanFilter(dim_x=8, dim_z=4)
        
        # State transition matrix (constant velocity model)
        self.kf.F = np.array([
            [1, 0, 0, 0, 1, 0, 0, 0],  # x = x + vx
            [0, 1, 0, 0, 0, 1, 0, 0],  # y = y + vy
            [0, 0, 1, 0, 0, 0, 1, 0],  # w = w + vw
            [0, 0, 0, 1, 0, 0, 0, 1],  # h = h + vh
            [0, 0, 0, 0, 1, 0, 0, 0],  # vx = vx
            [0, 0, 0, 0, 0, 1, 0, 0],  # vy = vy
            [0, 0, 0, 0, 0, 0, 1, 0],  # vw = vw
            [0, 0, 0, 0, 0, 0, 0, 1]   # vh = vh
        ])
        
        # Measurement matrix (we only measure position and size)
        self.kf.H = np.array([
            [1, 0, 0, 0, 0, 0, 0, 0],  # x
            [0, 1, 0, 0, 0, 0, 0, 0],  # y
            [0, 0, 1, 0, 0, 0, 0, 0],  # w
            [0, 0, 0, 1, 0, 0, 0, 0]   # h
        ])
        
        # Initialize state with detection
        self.kf.x[:4] = initial_detection.xywh
        self.kf.x[4:] = 0  # Zero initial velocity (static assumption)
        
        # Initial uncertainty (higher for velocities)
        self.kf.P[4:, 4:] *= 1000  # High uncertainty for velocities
        self.kf.P[:4, :4] *= 10    # Lower uncertainty for position
        
        # Process noise (very low for static objects)
        self.kf.Q[4:, 4:] *= 0.01  # Minimal velocity changes expected
        self.kf.Q[:4, :4] *= 0.1   # Small position changes expected
        
        # Measurement noise
        self.kf.R *= 10.0
        
        self.time_since_update = 0
        self.history: List[Detection] = []
        self.hits = 1
        self.age = 1
        
    def predict(self) -> np.ndarray:
        """
        Predict next state
        
        Returns:
            Predicted bounding box in tlbr format
        """
        # Handle numerical stability
        if np.trace(self.kf.P[4:, 4:]) > 1e4:
            self.kf.P[4:, 4:] *= 0.01
            
        self.kf.predict()
        self.age += 1
        self.time_since_update += 1
        
        return self.get_state()
    
    def update(self, detection: Detection) -> None:
        """
        Update filter with new detection
        
        Args:
            detection: New detection measurement
        """
        self.time_since_update = 0
        self.history.append(detection)
        self.hits += 1
        
        # Perform Kalman update
        self.kf.update(detection.xywh)
        
    def get_state(self) -> np.ndarray:
        """
        Get current state estimate
        
        Returns:
            Bounding box in tlbr format
        """
        x, y, w, h = self.kf.x[:4]
        return np.array([
            x - w/2,  # x1
            y - h/2,  # y1
            x + w/2,  # x2
            y + h/2   # y2
        ])
    
    def get_velocity(self) -> np.ndarray:
        """
        Get current velocity estimate
        
        Returns:
            Velocity vector [vx, vy]
        """
        return self.kf.x[4:6]


def batch_predict_kalman(kalman_trackers: List[KalmanBoxTracker]) -> np.ndarray:
    """
    Batch prediction for multiple Kalman filters
    
    Args:
        kalman_trackers: List of KalmanBoxTracker instances
        
    Returns:
        Array of predicted bounding boxes in tlbr format
    """
    if not kalman_trackers:
        return np.array([])
    
    # Collect predicted states
    predictions = np.zeros((len(kalman_trackers), 4))
    
    for i, tracker in enumerate(kalman_trackers):
        # Predict and get state
        tracker.predict()
        predictions[i] = tracker.get_state()
    
    return predictions

================
File: argus_track/trackers/__init__.py
================
"""Tracking algorithms"""

from .bytetrack import ByteTrack
from .lightpost_tracker import LightPostTracker

__all__ = ["ByteTrack", "LightPostTracker"]

================
File: argus_track/trackers/bytetrack.py
================
# argus_track/trackers/bytetrack.py

"""ByteTrack core implementation"""

import logging
from typing import List, Dict, Tuple
import numpy as np
from scipy.optimize import linear_sum_assignment

from ..config import TrackerConfig
from ..core import Detection, Track
from ..filters import KalmanBoxTracker, batch_predict_kalman
from ..utils import calculate_iou, calculate_iou_matrix


class ByteTrack:
    """
    ByteTrack multi-object tracker optimized for light posts
    
    This implementation uses a two-stage association strategy:
    1. Match high-confidence detections with existing tracks
    2. Match low-confidence detections with unmatched tracks
    
    Optimizations for static objects:
    - Extended track buffer for better persistence
    - Higher IoU thresholds for matching
    - Reduced process noise in Kalman filter
    - Vectorized operations for better performance
    """
    
    def __init__(self, config: TrackerConfig):
        """
        Initialize ByteTrack with configuration
        
        Args:
            config: Tracker configuration
        """
        self.config = config
        self.logger = logging.getLogger(f"{__name__}.ByteTrack")
        
        # Track management
        self.tracks: Dict[int, Track] = {}
        self.track_id_counter = 0
        self.frame_id = 0
        
        # Track pools
        self.active_tracks: List[Track] = []
        self.lost_tracks: List[Track] = []
        self.removed_tracks: List[Track] = []
        
    def update(self, detections: List[Detection]) -> List[Track]:
        """
        Update tracker with new detections
        
        Args:
            detections: List of detections for current frame
            
        Returns:
            List of active tracks
        """
        self.frame_id += 1
        
        # Filter detections by size
        valid_detections = [d for d in detections 
                          if d.area >= self.config.min_box_area]
        
        # Split into high and low confidence
        high_conf_dets = []
        low_conf_dets = []
        
        for det in valid_detections:
            if det.score >= self.config.track_thresh:
                high_conf_dets.append(det)
            else:
                low_conf_dets.append(det)
        
        # Predict current tracks - use vectorized prediction if possible
        if self.active_tracks:
            # Batch prediction for better performance
            kalman_trackers = [track.kalman_filter for track in self.active_tracks]
            batch_predict_kalman(kalman_trackers)
        
        # First association: high confidence detections with active tracks
        matches1, unmatched_tracks1, unmatched_dets1 = self._associate(
            self.active_tracks, 
            high_conf_dets,
            thresh=self.config.match_thresh
        )
        
        # Update matched tracks
        for track_idx, det_idx in matches1:
            track = self.active_tracks[track_idx]
            detection = high_conf_dets[det_idx]
            self._update_track(track, detection)
        
        # Second association: low confidence detections with unmatched tracks
        remaining_tracks = [self.active_tracks[i] for i in unmatched_tracks1]
        matches2, unmatched_tracks2, unmatched_dets2 = self._associate(
            remaining_tracks,
            low_conf_dets,
            thresh=0.5  # Lower threshold for second stage
        )
        
        # Update with low confidence matches
        for track_idx, det_idx in matches2:
            track = remaining_tracks[track_idx]
            detection = low_conf_dets[det_idx]
            self._update_track(track, detection)
        
        # Handle unmatched tracks
        for idx in unmatched_tracks2:
            track = remaining_tracks[idx]
            self._mark_lost(track)
        
        # Create new tracks from unmatched high confidence detections
        for idx in unmatched_dets1:
            detection = high_conf_dets[idx]
            self._create_track(detection)
        
        # Update track lists
        self._update_track_lists()
        
        return self.active_tracks
    
    def _associate(self, tracks: List[Track], detections: List[Detection],
                   thresh: float) -> Tuple[List[Tuple[int, int]], List[int], List[int]]:
        """
        Associate tracks with detections using IoU
        
        Args:
            tracks: List of tracks
            detections: List of detections
            thresh: IoU threshold for matching
            
        Returns:
            (matches, unmatched_tracks, unmatched_detections)
        """
        if len(tracks) == 0 or len(detections) == 0:
            return [], list(range(len(tracks))), list(range(len(detections)))
        
        # Calculate IoU matrix - using optimized function
        iou_matrix = calculate_iou_matrix(tracks, detections)
        
        # Apply Hungarian algorithm
        cost_matrix = 1 - iou_matrix  # Convert to cost
        row_indices, col_indices = linear_sum_assignment(cost_matrix)
        
        # Filter matches by threshold
        matches = []
        unmatched_tracks = set(range(len(tracks)))
        unmatched_detections = set(range(len(detections)))
        
        for row, col in zip(row_indices, col_indices):
            if iou_matrix[row, col] >= thresh:
                matches.append((row, col))
                unmatched_tracks.discard(row)
                unmatched_detections.discard(col)
        
        return matches, list(unmatched_tracks), list(unmatched_detections)
    
    def _update_track(self, track: Track, detection: Detection) -> None:
        """
        Update track with new detection
        
        Args:
            track: Track to update
            detection: New detection
        """
        track.kalman_filter.update(detection)
        track.detections.append(detection)
        track.hits += 1
        track.time_since_update = 0
        
        # Update track state
        if track.state == 'tentative' and track.hits >= 3:
            track.state = 'confirmed'
            self.logger.debug(f"Track {track.track_id} confirmed")
    
    def _create_track(self, detection: Detection) -> Track:
        """
        Create new track from detection
        
        Args:
            detection: Initial detection
            
        Returns:
            New track
        """
        track_id = self.track_id_counter
        self.track_id_counter += 1
        
        track = Track(
            track_id=track_id,
            detections=[detection],
            kalman_filter=KalmanBoxTracker(detection),
            state='tentative',
            hits=1,
            age=1,
            time_since_update=0,
            start_frame=self.frame_id
        )
        
        self.tracks[track_id] = track
        self.active_tracks.append(track)
        
        self.logger.debug(f"Created new track {track_id}")
        return track
    
    def _mark_lost(self, track: Track) -> None:
        """Mark track as lost"""
        track.state = 'lost'
        track.time_since_update += 1
        self.lost_tracks.append(track)
        
    def _update_track_lists(self) -> None:
        """Update track lists based on current states"""
        # Separate active and lost tracks
        new_active = []
        new_lost = []
        
        for track in self.active_tracks:
            if track.state in ['tentative', 'confirmed']:
                new_active.append(track)
            else:
                new_lost.append(track)
        
        # Handle lost tracks
        for track in self.lost_tracks:
            track.time_since_update += 1
            if track.time_since_update > self.config.track_buffer:
                track.state = 'removed'
                self.removed_tracks.append(track)
            else:
                new_lost.append(track)
        
        self.active_tracks = new_active
        self.lost_tracks = new_lost
    
    def get_all_tracks(self) -> Dict[int, Track]:
        """Get all tracks (active, lost, and removed)"""
        return self.tracks.copy()
    
    def reset(self) -> None:
        """Reset tracker to initial state"""
        self.tracks.clear()
        self.track_id_counter = 0
        self.frame_id = 0
        self.active_tracks.clear()
        self.lost_tracks.clear()
        self.removed_tracks.clear()
        self.logger.info("Tracker reset")
    
    def merge_duplicate_tracks(self, distance_threshold: float = 10.0) -> Dict[int, List[int]]:
        """
        Identify and merge duplicate tracks that likely belong to the same object
        
        Args:
            distance_threshold: Maximum center distance to consider duplicates
            
        Returns:
            Dictionary mapping primary track_id to list of duplicate track_ids
        """
        duplicates = {}
        processed = set()
        
        # First, identify duplicates
        for i, track1 in enumerate(self.active_tracks):
            if track1.track_id in processed:
                continue
                
            similar_tracks = []
            
            for j, track2 in enumerate(self.active_tracks[i+1:], i+1):
                if track2.track_id in processed:
                    continue
                
                # Skip if tracks have very different ages
                if abs(track1.age - track2.age) > 30:
                    continue
                
                # Get current positions
                bbox1 = track1.to_tlbr()
                bbox2 = track2.to_tlbr()
                
                # Calculate center points
                center1 = np.array([(bbox1[0] + bbox1[2])/2, (bbox1[1] + bbox1[3])/2])
                center2 = np.array([(bbox2[0] + bbox2[2])/2, (bbox2[1] + bbox2[3])/2])
                
                # Calculate distance
                distance = np.linalg.norm(center1 - center2)
                
                # If tracks are close, mark as duplicates
                if distance < distance_threshold:
                    similar_tracks.append(track2.track_id)
                    processed.add(track2.track_id)
            
            if similar_tracks:
                duplicates[track1.track_id] = similar_tracks
        
        # Now merge the duplicates (keep the one with more hits)
        for main_id, duplicate_ids in duplicates.items():
            main_track = self.tracks[main_id]
            
            for dup_id in duplicate_ids:
                dup_track = self.tracks[dup_id]
                
                # Keep the track with more hits
                if dup_track.hits > main_track.hits:
                    # Move the duplicate's detections to the main track
                    main_track.detections.extend(dup_track.detections)
                    main_track.hits += dup_track.hits
                
                # Mark duplicate as removed
                dup_track.state = 'removed'
                
                # Remove from active tracks
                if dup_track in self.active_tracks:
                    self.active_tracks.remove(dup_track)
        
        # Update track lists to reflect changes
        self._update_track_lists()
                
        return duplicates

================
File: argus_track/trackers/lightpost_tracker.py
================
# argus_track/trackers/lightpost_tracker.py

"""Light Post Tracker with GPS integration"""

import json
import time
import logging
from pathlib import Path
from typing import List, Dict, Optional, Any, Tuple
import numpy as np
import cv2

from ..config import TrackerConfig, CameraConfig
from ..core import Detection, Track, GPSData
from ..detectors import ObjectDetector
from .bytetrack import ByteTrack
from ..utils.visualization import draw_tracks, create_track_overlay
from ..utils.io import save_tracking_results, load_gps_data
from ..utils.gps_utils import compute_average_location, filter_gps_outliers, GeoLocation


class LightPostTracker:
    """
    Complete light post tracking system with GPS integration
    
    This class orchestrates the entire tracking pipeline:
    1. Object detection using configurable detector
    2. Multi-object tracking with ByteTrack
    3. GPS data synchronization
    4. Geolocation estimation
    5. Results visualization and saving
    """
    
    def __init__(self, config: TrackerConfig, 
                 detector: ObjectDetector,
                 camera_config: Optional[CameraConfig] = None):
        """
        Initialize light post tracker
        
        Args:
            config: Tracker configuration
            detector: Object detection module
            camera_config: Camera calibration configuration
        """
        self.config = config
        self.detector = detector
        self.tracker = ByteTrack(config)
        self.logger = logging.getLogger(f"{__name__}.LightPostTracker")
        
        # Camera calibration
        self.camera_config = camera_config
        
        # GPS tracking
        self.gps_tracks: Dict[int, List[GPSData]] = {}
        
        # Track locations
        self.track_locations: Dict[int, GeoLocation] = {}
        
        # Performance monitoring
        self.processing_times = []
        
    def process_video(self, video_path: str, 
                     gps_data: Optional[List[GPSData]] = None,
                     output_path: Optional[str] = None,
                     save_results: bool = True) -> Dict[int, List[Dict]]:
        """
        Process complete video with tracking
        
        Args:
            video_path: Path to input video
            gps_data: Optional GPS data synchronized with frames
            output_path: Optional path for output video
            save_results: Whether to save tracking results
            
        Returns:
            Dictionary of tracks with their complete history
        """
        self.logger.info(f"Processing video: {video_path}")
        
        # Open video
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            error_msg = f"Could not open video: {video_path}"
            self.logger.error(error_msg)
            raise IOError(error_msg)
            
        fps = cap.get(cv2.CAP_PROP_FPS)
        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        
        # Setup video writer if output path provided
        out_writer = None
        if output_path:
            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            out_writer = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
        
        # Process frames
        all_tracks = {}
        frame_idx = 0
        
        try:
            while True:
                ret, frame = cap.read()
                if not ret:
                    break
                
                start_time = time.time()
                
                # Detect objects
                raw_detections = self.detector.detect(frame)
                
                # Convert to Detection objects
                detections = []
                for i, det in enumerate(raw_detections):
                    detections.append(Detection(
                        bbox=np.array(det['bbox']),
                        score=det['score'],
                        class_id=det['class_id'],
                        frame_id=frame_idx
                    ))
                
                # Update tracker - use batched Kalman prediction for efficiency
                tracks = self.tracker.update(detections)
                
                # Update GPS data if available
                if gps_data and frame_idx < len(gps_data):
                    self._update_gps_tracks(tracks, gps_data[frame_idx])
                
                # Store track data
                for track in tracks:
                    if track.track_id not in all_tracks:
                        all_tracks[track.track_id] = []
                    
                    all_tracks[track.track_id].append({
                        'frame': frame_idx,
                        'bbox': track.to_tlbr().tolist(),
                        'score': track.detections[-1].score if track.detections else 0,
                        'state': track.state,
                        'hits': track.hits
                    })
                
                # Visualize if output requested
                if out_writer:
                    vis_frame = draw_tracks(frame, tracks)
                    out_writer.write(vis_frame)
                
                # Performance monitoring
                process_time = time.time() - start_time
                self.processing_times.append(process_time)
                
                # Progress logging
                if frame_idx % 100 == 0:
                    avg_time = np.mean(self.processing_times[-100:]) if self.processing_times else 0
                    self.logger.info(
                        f"Processed {frame_idx}/{frame_count} frames "
                        f"({frame_idx/frame_count*100:.1f}%) "
                        f"Avg time: {avg_time*1000:.1f}ms"
                    )
                
                frame_idx += 1
                
        except Exception as e:
            self.logger.error(f"Error processing video: {e}")
            raise
            
        finally:
            # Cleanup
            cap.release()
            if out_writer:
                out_writer.release()
            cv2.destroyAllWindows()
        
        # Estimate geolocations for static tracks
        if gps_data:
            self.estimate_track_locations()
        
        # Save results if requested
        if save_results:
            results_path = Path(video_path).with_suffix('.json')
            save_tracking_results(
                all_tracks, 
                results_path,
                metadata={
                    'total_frames': frame_idx,
                    'fps': fps,
                    'width': width,
                    'height': height,
                    'config': self.config.__dict__,
                    'processing_times': {
                        'mean': np.mean(self.processing_times) if self.processing_times else 0,
                        'std': np.std(self.processing_times) if self.processing_times else 0,
                        'min': np.min(self.processing_times) if self.processing_times else 0,
                        'max': np.max(self.processing_times) if self.processing_times else 0
                    }
                },
                gps_tracks=self.gps_tracks,
                track_locations={
                    k: v.__dict__ for k, v in self.track_locations.items()
                }
            )
        
        self.logger.info(f"Processing complete. Tracked {len(all_tracks)} objects")
        return all_tracks
    
    def process_frame(self, frame: np.ndarray, frame_idx: int,
                     gps_data: Optional[GPSData] = None) -> List[Track]:
        """
        Process a single frame
        
        Args:
            frame: Input frame
            frame_idx: Frame index
            gps_data: Optional GPS data for this frame
            
        Returns:
            List of active tracks
        """
        # Detect objects
        raw_detections = self.detector.detect(frame)
        
        # Convert to Detection objects
        detections = []
        for det in raw_detections:
            detections.append(Detection(
                bbox=np.array(det['bbox']),
                score=det['score'],
                class_id=det['class_id'],
                frame_id=frame_idx
            ))
        
        # Update tracker
        tracks = self.tracker.update(detections)
        
        # Update GPS data if available
        if gps_data:
            self._update_gps_tracks(tracks, gps_data)
        
        return tracks
    
    def _update_gps_tracks(self, tracks: List[Track], gps_data: GPSData) -> None:
        """
        Update GPS data for active tracks
        
        Args:
            tracks: Current active tracks
            gps_data: GPS data for current frame
        """
        for track in tracks:
            if track.track_id not in self.gps_tracks:
                self.gps_tracks[track.track_id] = []
            self.gps_tracks[track.track_id].append(gps_data)
    
    def estimate_track_locations(self) -> Dict[int, GeoLocation]:
        """
        Estimate geolocation for all tracks
        
        Returns:
            Dictionary mapping track_id to GeoLocation
        """
        static_objects = self.analyze_static_objects()
        
        for track_id, is_static in static_objects.items():
            # Only compute locations for static objects
            if not is_static or track_id not in self.gps_tracks:
                continue
            
            gps_points = self.gps_tracks[track_id]
            
            # Filter outliers
            filtered_points = filter_gps_outliers(gps_points)
            
            # Compute average location
            location = compute_average_location(filtered_points)
            
            self.track_locations[track_id] = location
            
            self.logger.debug(
                f"Track {track_id} located at ({location.latitude:.6f}, {location.longitude:.6f}) "
                f"reliability: {location.reliability:.2f}"
            )
        
        return self.track_locations
    
    def get_static_locations(self) -> Dict[int, GeoLocation]:
        """
        Get geolocations of all static objects
        
        Returns:
            Dictionary mapping track_id to GeoLocation
        """
        # Ensure locations are estimated
        if not self.track_locations:
            self.estimate_track_locations()
            
        return {k: v for k, v in self.track_locations.items() if v.reliability > 0.5}
    
    def analyze_static_objects(self) -> Dict[int, bool]:
        """
        Analyze which tracked objects are static
        
        Returns:
            Dictionary mapping track_id to is_static boolean
        """
        static_analysis = {}
        
        for track_id, track in self.tracker.tracks.items():
            if len(track.detections) < self.config.min_static_frames:
                static_analysis[track_id] = False
                continue
            
            # Calculate movement over recent frames
            recent_detections = track.detections[-self.config.min_static_frames:]
            positions = np.array([det.xywh[:2] for det in recent_detections])
            
            # Calculate standard deviation of positions
            movement = np.std(positions, axis=0)
            
            # Check if movement is below threshold
            is_static = np.all(movement < self.config.static_threshold)
            static_analysis[track_id] = is_static
            
            if is_static:
                self.logger.debug(f"Track {track_id} identified as static object")
        
        return static_analysis
    
    def get_track_statistics(self) -> Dict[str, Any]:
        """Get comprehensive tracking statistics"""
        tracks = self.tracker.get_all_tracks()
        
        return {
            'total_tracks': len(tracks),
            'active_tracks': len(self.tracker.active_tracks),
            'lost_tracks': len(self.tracker.lost_tracks),
            'removed_tracks': len(self.tracker.removed_tracks),
            'total_frames': self.tracker.frame_id,
            'avg_track_length': np.mean([track.age for track in tracks.values()]) if tracks else 0,
            'static_objects': sum(1 for is_static in self.analyze_static_objects().values() if is_static),
            'located_objects': len(self.track_locations)
        }
    
    def export_locations_to_geojson(self, output_path: str) -> None:
        """
        Export static object locations to GeoJSON format
        
        Args:
            output_path: Path to output GeoJSON file
        """
        if not self.track_locations:
            self.estimate_track_locations()
            
        # Filter to only include reliable locations
        reliable_locations = {k: v for k, v in self.track_locations.items() 
                             if v.reliability > 0.5}
            
        features = []
        for track_id, location in reliable_locations.items():
            feature = {
                "type": "Feature",
                "geometry": {
                    "type": "Point",
                    "coordinates": [location.longitude, location.latitude]
                },
                "properties": {
                    "track_id": track_id,
                    "reliability": location.reliability,
                    "accuracy": location.accuracy
                }
            }
            features.append(feature)
            
        geojson = {
            "type": "FeatureCollection",
            "features": features
        }
        
        with open(output_path, 'w') as f:
            json.dump(geojson, f, indent=2)
            
        self.logger.info(f"Exported {len(features)} locations to GeoJSON: {output_path}")

================
File: argus_track/utils/__init__.py
================
"""Utility functions for ByteTrack system"""

from .iou import calculate_iou, calculate_iou_matrix
from .visualization import draw_tracks, create_track_overlay
from .io import save_tracking_results, load_gps_data, setup_logging
from .gps_utils import GPSInterpolator, CoordinateTransformer
from .performance import PerformanceMonitor, PerformanceMetrics
from .config_validator import ConfigValidator, ConfigLoader

__all__ = [
    "calculate_iou",
    "calculate_iou_matrix",
    "draw_tracks",
    "create_track_overlay",
    "save_tracking_results",
    "load_gps_data",
    "setup_logging",
    "GPSInterpolator",
    "CoordinateTransformer",
    "PerformanceMonitor",
    "PerformanceMetrics",
    "ConfigValidator",
    "ConfigLoader"
]

================
File: argus_track/utils/config_validator.py
================
"""Configuration validation utilities"""

from typing import Dict, List, Any, Optional
from dataclasses import fields
import yaml
import json
from pathlib import Path

from ..config import TrackerConfig, DetectorConfig, CameraConfig


class ConfigValidator:
    """Validate and sanitize configuration parameters"""
    
    @staticmethod
    def validate_tracker_config(config: TrackerConfig) -> List[str]:
        """
        Validate tracker configuration
        
        Args:
            config: TrackerConfig instance
            
        Returns:
            List of validation errors
        """
        errors = []
        
        # Validate thresholds
        if not 0 <= config.track_thresh <= 1:
            errors.append(f"track_thresh must be between 0 and 1, got {config.track_thresh}")
        
        if not 0 <= config.match_thresh <= 1:
            errors.append(f"match_thresh must be between 0 and 1, got {config.match_thresh}")
        
        # Validate buffer sizes
        if config.track_buffer < 1:
            errors.append(f"track_buffer must be at least 1, got {config.track_buffer}")
        
        if config.track_buffer > 300:
            errors.append(f"track_buffer is very large ({config.track_buffer}), this may cause memory issues")
        
        # Validate area threshold
        if config.min_box_area < 0:
            errors.append(f"min_box_area must be non-negative, got {config.min_box_area}")
        
        # Validate static detection parameters
        if config.static_threshold <= 0:
            errors.append(f"static_threshold must be positive, got {config.static_threshold}")
        
        if config.min_static_frames < 1:
            errors.append(f"min_static_frames must be at least 1, got {config.min_static_frames}")
        
        return errors
    
    @staticmethod
    def validate_detector_config(config: DetectorConfig) -> List[str]:
        """
        Validate detector configuration
        
        Args:
            config: DetectorConfig instance
            
        Returns:
            List of validation errors
        """
        errors = []
        
        # Check paths exist
        if not Path(config.model_path).exists():
            errors.append(f"Model path does not exist: {config.model_path}")
        
        if not Path(config.config_path).exists():
            errors.append(f"Config path does not exist: {config.config_path}")
        
        # Validate thresholds
        if not 0 <= config.confidence_threshold <= 1:
            errors.append(f"confidence_threshold must be between 0 and 1, got {config.confidence_threshold}")
        
        if not 0 <= config.nms_threshold <= 1:
            errors.append(f"nms_threshold must be between 0 and 1, got {config.nms_threshold}")
        
        # Validate target classes
        if config.target_classes is not None and not config.target_classes:
            errors.append("target_classes is empty, no objects will be detected")
        
        return errors
    
    @staticmethod
    def validate_camera_config(config: CameraConfig) -> List[str]:
        """
        Validate camera configuration
        
        Args:
            config: CameraConfig instance
            
        Returns:
            List of validation errors
        """
        errors = []
        
        # Validate camera matrix
        if len(config.camera_matrix) != 3 or len(config.camera_matrix[0]) != 3:
            errors.append("camera_matrix must be a 3x3 matrix")
        
        # Validate distortion coefficients
        if len(config.distortion_coeffs) < 4:
            errors.append("distortion_coeffs must have at least 4 elements")
        
        # Validate image dimensions
        if config.image_width <= 0:
            errors.append(f"image_width must be positive, got {config.image_width}")
        
        if config.image_height <= 0:
            errors.append(f"image_height must be positive, got {config.image_height}")
        
        return errors
    
    @staticmethod
    def sanitize_config(config_dict: Dict[str, Any], 
                       config_class: type) -> Dict[str, Any]:
        """
        Sanitize configuration dictionary
        
        Args:
            config_dict: Raw configuration dictionary
            config_class: Target configuration class
            
        Returns:
            Sanitized configuration dictionary
        """
        # Get valid field names
        valid_fields = {f.name for f in fields(config_class)}
        
        # Filter out invalid fields
        sanitized = {
            k: v for k, v in config_dict.items() 
            if k in valid_fields
        }
        
        # Add missing fields with defaults
        for field in fields(config_class):
            if field.name not in sanitized and field.default is not None:
                sanitized[field.name] = field.default
        
        return sanitized
    
    @staticmethod
    def merge_configs(base_config: Dict[str, Any], 
                     override_config: Dict[str, Any]) -> Dict[str, Any]:
        """
        Merge two configuration dictionaries
        
        Args:
            base_config: Base configuration
            override_config: Override configuration
            
        Returns:
            Merged configuration
        """
        merged = base_config.copy()
        
        for key, value in override_config.items():
            if isinstance(value, dict) and key in merged and isinstance(merged[key], dict):
                merged[key] = ConfigValidator.merge_configs(merged[key], value)
            else:
                merged[key] = value
        
        return merged


class ConfigLoader:
    """Load and validate configuration from various sources"""
    
    @staticmethod
    def load_from_file(filepath: str) -> Dict[str, Any]:
        """
        Load configuration from file
        
        Args:
            filepath: Path to configuration file
            
        Returns:
            Configuration dictionary
        """
        path = Path(filepath)
        
        if not path.exists():
            raise FileNotFoundError(f"Configuration file not found: {filepath}")
        
        if path.suffix in ['.yaml', '.yml']:
            with open(filepath, 'r') as f:
                return yaml.safe_load(f)
        elif path.suffix == '.json':
            with open(filepath, 'r') as f:
                return json.load(f)
        else:
            raise ValueError(f"Unsupported configuration format: {path.suffix}")
    
    @staticmethod
    def create_tracker_config(config_source: Optional[str] = None,
                            overrides: Optional[Dict[str, Any]] = None) -> TrackerConfig:
        """
        Create validated TrackerConfig
        
        Args:
            config_source: Path to configuration file
            overrides: Dictionary of override values
            
        Returns:
            Validated TrackerConfig instance
        """
        # Load base configuration
        if config_source:
            config_dict = ConfigLoader.load_from_file(config_source)
        else:
            config_dict = {}
        
        # Apply overrides
        if overrides:
            config_dict = ConfigValidator.merge_configs(config_dict, overrides)
        
        # Sanitize configuration
        config_dict = ConfigValidator.sanitize_config(config_dict, TrackerConfig)
        
        # Create config instance
        config = TrackerConfig(**config_dict)
        
        # Validate
        errors = ConfigValidator.validate_tracker_config(config)
        if errors:
            raise ValueError(f"Configuration validation failed: {'; '.join(errors)}")
        
        return config

================
File: argus_track/utils/gps_utils.py
================
# argus_track/utils/gps_utils.py

"""Enhanced GPS utilities for tracking"""

import numpy as np
from typing import List, Tuple, Optional, Dict
from scipy.interpolate import interp1d
import pyproj
from dataclasses import dataclass

from ..core import GPSData


class GPSInterpolator:
    """Interpolate GPS data between frames"""
    
    def __init__(self, gps_data: List[GPSData]):
        """
        Initialize GPS interpolator
        
        Args:
            gps_data: List of GPS data points
        """
        self.gps_data = sorted(gps_data, key=lambda x: x.timestamp)
        self.timestamps = np.array([gps.timestamp for gps in self.gps_data])
        
        # Create interpolation functions
        self.lat_interp = interp1d(
            self.timestamps,
            [gps.latitude for gps in self.gps_data],
            kind='linear',
            fill_value='extrapolate'
        )
        self.lon_interp = interp1d(
            self.timestamps,
            [gps.longitude for gps in self.gps_data],
            kind='linear',
            fill_value='extrapolate'
        )
        self.heading_interp = interp1d(
            self.timestamps,
            [gps.heading for gps in self.gps_data],
            kind='linear',
            fill_value='extrapolate'
        )
    
    def interpolate(self, timestamp: float) -> GPSData:
        """
        Interpolate GPS data for a specific timestamp
        
        Args:
            timestamp: Target timestamp
            
        Returns:
            Interpolated GPS data
        """
        return GPSData(
            timestamp=timestamp,
            latitude=float(self.lat_interp(timestamp)),
            longitude=float(self.lon_interp(timestamp)),
            altitude=0.0,  # We're not focusing on altitude
            heading=float(self.heading_interp(timestamp)),
            accuracy=1.0  # Interpolated accuracy
        )
    
    def get_range(self) -> Tuple[float, float]:
        """Get timestamp range of GPS data"""
        return self.timestamps[0], self.timestamps[-1]


class CoordinateTransformer:
    """Transform between GPS coordinates and local coordinate systems"""
    
    def __init__(self, reference_lat: float, reference_lon: float):
        """
        Initialize transformer with reference point
        
        Args:
            reference_lat: Reference latitude
            reference_lon: Reference longitude
        """
        self.reference_lat = reference_lat
        self.reference_lon = reference_lon
        
        # Setup projections
        self.wgs84 = pyproj.CRS("EPSG:4326")  # GPS coordinates
        self.utm = pyproj.CRS(f"EPSG:{self._get_utm_zone()}")
        self.transformer = pyproj.Transformer.from_crs(
            self.wgs84, self.utm, always_xy=True
        )
        self.inverse_transformer = pyproj.Transformer.from_crs(
            self.utm, self.wgs84, always_xy=True
        )
        
        # Calculate reference point in UTM
        self.ref_x, self.ref_y = self.transformer.transform(
            reference_lon, reference_lat
        )
    
    def _get_utm_zone(self) -> int:
        """Get UTM zone for reference point"""
        zone = int((self.reference_lon + 180) / 6) + 1
        if self.reference_lat >= 0:
            return 32600 + zone  # Northern hemisphere
        else:
            return 32700 + zone  # Southern hemisphere
    
    def gps_to_local(self, lat: float, lon: float) -> Tuple[float, float]:
        """
        Convert GPS coordinates to local coordinate system
        
        Args:
            lat: Latitude
            lon: Longitude
            
        Returns:
            (x, y) in meters from reference point
        """
        utm_x, utm_y = self.transformer.transform(lon, lat)
        return utm_x - self.ref_x, utm_y - self.ref_y
    
    def local_to_gps(self, x: float, y: float) -> Tuple[float, float]:
        """
        Convert local coordinates to GPS
        
        Args:
            x: X coordinate in meters from reference
            y: Y coordinate in meters from reference
            
        Returns:
            (latitude, longitude)
        """
        utm_x = x + self.ref_x
        utm_y = y + self.ref_y
        lon, lat = self.inverse_transformer.transform(utm_x, utm_y)
        return lat, lon
    
    def distance(self, lat1: float, lon1: float, 
                 lat2: float, lon2: float) -> float:
        """
        Calculate distance between two GPS points
        
        Args:
            lat1, lon1: First point
            lat2, lon2: Second point
            
        Returns:
            Distance in meters
        """
        x1, y1 = self.gps_to_local(lat1, lon1)
        x2, y2 = self.gps_to_local(lat2, lon2)
        return np.sqrt((x2 - x1)**2 + (y2 - y1)**2)


@dataclass
class GeoLocation:
    """Represents a geographic location with reliability information"""
    latitude: float
    longitude: float
    accuracy: float = 1.0  # Accuracy in meters
    reliability: float = 1.0  # Value between 0 and 1
    timestamp: Optional[float] = None


def sync_gps_with_frames(gps_data: List[GPSData], 
                         video_fps: float,
                         start_timestamp: Optional[float] = None) -> List[GPSData]:
    """
    Synchronize GPS data with video frames
    
    Args:
        gps_data: List of GPS data points
        video_fps: Video frame rate
        start_timestamp: Optional start timestamp
        
    Returns:
        List of GPS data aligned with frames
    """
    if not gps_data:
        return []
    
    # Sort GPS data by timestamp
    gps_data = sorted(gps_data, key=lambda x: x.timestamp)
    
    # Determine start timestamp
    if start_timestamp is None:
        start_timestamp = gps_data[0].timestamp
    
    # Create interpolator
    interpolator = GPSInterpolator(gps_data)
    
    # Generate frame-aligned GPS data
    frame_gps = []
    frame_duration = 1.0 / video_fps
    
    timestamp = start_timestamp
    while timestamp <= gps_data[-1].timestamp:
        frame_gps.append(interpolator.interpolate(timestamp))
        timestamp += frame_duration
    
    return frame_gps


def compute_average_location(locations: List[GPSData]) -> GeoLocation:
    """
    Compute the average location from multiple GPS points
    
    Args:
        locations: List of GPS data points
        
    Returns:
        Average location with reliability score
    """
    if not locations:
        return GeoLocation(0.0, 0.0, 0.0, 0.0)
    
    # Simple weighted average based on accuracy
    weights = np.array([1.0 / max(loc.accuracy, 0.1) for loc in locations])
    weights = weights / np.sum(weights)  # Normalize
    
    avg_lat = np.sum([loc.latitude * w for loc, w in zip(locations, weights)])
    avg_lon = np.sum([loc.longitude * w for loc, w in zip(locations, weights)])
    
    # Calculate reliability based on consistency of points
    if len(locations) > 1:
        # Create transformer using the first point as reference
        transformer = CoordinateTransformer(locations[0].latitude, locations[0].longitude)
        
        # Calculate standard deviation in meters
        distances = []
        for loc in locations:
            dist = transformer.distance(loc.latitude, loc.longitude, avg_lat, avg_lon)
            distances.append(dist)
        
        std_dev = np.std(distances)
        reliability = 1.0 / (1.0 + std_dev / 10.0)  # Decreases with higher standard deviation
        reliability = min(1.0, max(0.1, reliability))  # Clamp between 0.1 and 1.0
    else:
        reliability = 0.5  # Only one point, medium reliability
    
    # Average accuracy is the weighted average of individual accuracies
    avg_accuracy = np.sum([loc.accuracy * w for loc, w in zip(locations, weights)])
    
    # Use the latest timestamp
    latest_timestamp = max([loc.timestamp for loc in locations])
    
    return GeoLocation(
        latitude=avg_lat,
        longitude=avg_lon,
        accuracy=avg_accuracy,
        reliability=reliability,
        timestamp=latest_timestamp
    )


def filter_gps_outliers(locations: List[GPSData], 
                       threshold_meters: float = 30.0) -> List[GPSData]:
    """
    Filter outliers from GPS data using DBSCAN clustering
    
    Args:
        locations: List of GPS data points
        threshold_meters: Distance threshold for outlier detection
        
    Returns:
        Filtered list of GPS data points
    """
    if len(locations) <= 2:
        return locations
    
    from sklearn.cluster import DBSCAN
    
    # Create transformer using the first point as reference
    transformer = CoordinateTransformer(locations[0].latitude, locations[0].longitude)
    
    # Convert to local coordinates
    local_points = []
    for loc in locations:
        x, y = transformer.gps_to_local(loc.latitude, loc.longitude)
        local_points.append([x, y])
    
    # Cluster points
    clustering = DBSCAN(eps=threshold_meters, min_samples=1).fit(local_points)
    
    # Find the largest cluster
    labels = clustering.labels_
    unique_labels, counts = np.unique(labels, return_counts=True)
    largest_cluster = unique_labels[np.argmax(counts)]
    
    # Keep only points from the largest cluster
    filtered_locations = [loc for i, loc in enumerate(locations) if labels[i] == largest_cluster]
    
    return filtered_locations

================
File: argus_track/utils/io.py
================
# argus_track/utils/io.py

"""I/O utilities for loading and saving tracking data"""

import json
import logging
from pathlib import Path
from typing import Dict, List, Optional, Any
import csv

import numpy as np

from ..core import GPSData, Track


def setup_logging(log_file: Optional[str] = None, 
                 level: int = logging.INFO) -> None:
    """
    Setup logging configuration
    
    Args:
        log_file: Optional log file path
        level: Logging level
    """
    handlers = [logging.StreamHandler()]
    
    if log_file:
        handlers.append(logging.FileHandler(log_file))
    
    logging.basicConfig(
        level=level,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=handlers
    )


def save_tracking_results(tracks: Dict[int, List[Dict]], 
                         output_path: Path,
                         metadata: Optional[Dict[str, Any]] = None,
                         gps_tracks: Optional[Dict[int, List[GPSData]]] = None,
                         track_locations: Optional[Dict[int, Dict]] = None) -> None:
    """
    Save tracking results to JSON file
    
    Args:
        tracks: Dictionary of track histories
        output_path: Path for output file
        metadata: Optional metadata to include
        gps_tracks: Optional GPS data for tracks
        track_locations: Optional estimated locations for tracks
    """
    results = {
        'metadata': metadata or {},
        'tracks': tracks
    }
    
    # Add GPS data if provided
    if gps_tracks:
        results['gps_tracks'] = {
            track_id: [gps.to_dict() for gps in gps_list]
            for track_id, gps_list in gps_tracks.items()
        }
        
    # Add track locations if provided
    if track_locations:
        results['track_locations'] = track_locations
    
    # Save to file
    with open(output_path, 'w') as f:
        json.dump(results, f, indent=2)
    
    logging.info(f"Saved tracking results to {output_path}")


def load_tracking_results(input_path: Path) -> Dict[str, Any]:
    """
    Load tracking results from JSON file
    
    Args:
        input_path: Path to input file
        
    Returns:
        Dictionary with tracking results
    """
    with open(input_path, 'r') as f:
        results = json.load(f)
    
    logging.info(f"Loaded tracking results from {input_path}")
    return results


def load_gps_data(gps_file: str) -> List[GPSData]:
    """
    Load GPS data from file
    
    Args:
        gps_file: Path to GPS data file (CSV format)
        
    Returns:
        List of GPS data points
    """
    gps_data = []
    
    with open(gps_file, 'r') as f:
        reader = csv.reader(f)
        # Skip header if exists
        header = next(reader, None)
        
        try:
            for row in reader:
                if len(row) >= 5:
                    gps_data.append(GPSData(
                        timestamp=float(row[0]),
                        latitude=float(row[1]),
                        longitude=float(row[2]),
                        altitude=float(row[3]) if len(row) > 3 else 0.0,
                        heading=float(row[4]) if len(row) > 4 else 0.0,
                        accuracy=float(row[5]) if len(row) > 5 else 1.0
                    ))
        except ValueError as e:
            logging.error(f"Error parsing GPS data: {e}")
            logging.error(f"Problematic row: {row}")
            raise
    
    logging.info(f"Loaded {len(gps_data)} GPS data points from {gps_file}")
    return gps_data


def save_gps_data(gps_data: List[GPSData], output_path: str) -> None:
    """
    Save GPS data to CSV file
    
    Args:
        gps_data: List of GPS data points
        output_path: Path for output file
    """
    with open(output_path, 'w', newline='') as f:
        writer = csv.writer(f)
        # Write header
        writer.writerow(['timestamp', 'latitude', 'longitude', 
                        'altitude', 'heading', 'accuracy'])
        
        # Write data
        for gps in gps_data:
            writer.writerow([
                gps.timestamp,
                gps.latitude,
                gps.longitude,
                gps.altitude,
                gps.heading,
                gps.accuracy
            ])
    
    logging.info(f"Saved {len(gps_data)} GPS data points to {output_path}")


def export_locations_to_csv(track_locations: Dict[int, Dict],
                           output_path: str) -> None:
    """
    Export estimated track locations to CSV
    
    Args:
        track_locations: Dictionary of track locations
        output_path: Output CSV path
    """
    with open(output_path, 'w', newline='') as f:
        writer = csv.writer(f)
        writer.writerow(['track_id', 'latitude', 'longitude', 
                         'accuracy', 'reliability', 'timestamp'])
        
        for track_id, location in track_locations.items():
            writer.writerow([
                track_id,
                location['latitude'],
                location['longitude'],
                location.get('accuracy', 1.0),
                location.get('reliability', 1.0),
                location.get('timestamp', '')
            ])
    
    logging.info(f"Exported {len(track_locations)} locations to CSV: {output_path}")


def export_tracks_to_csv(tracks: Dict[int, Track], 
                        output_path: str) -> None:
    """
    Export track data to CSV format
    
    Args:
        tracks: Dictionary of tracks
        output_path: Path for output CSV file
    """
    with open(output_path, 'w', newline='') as f:
        writer = csv.writer(f)
        # Write header
        writer.writerow(['track_id', 'frame', 'x1', 'y1', 'x2', 'y2', 
                        'state', 'hits', 'age'])
        
        # Write track data
        for track_id, track in tracks.items():
            for detection in track.detections:
                x1, y1, x2, y2 = detection.tlbr
                writer.writerow([
                    track_id,
                    detection.frame_id,
                    x1, y1, x2, y2,
                    track.state,
                    track.hits,
                    track.age
                ])
    
    logging.info(f"Exported tracks to CSV: {output_path}")


def load_config_from_file(config_path: str) -> Dict[str, Any]:
    """
    Load configuration from YAML or JSON file
    
    Args:
        config_path: Path to configuration file
        
    Returns:
        Configuration dictionary
    """
    path = Path(config_path)
    
# argus_track/utils/io.py (continued)

    if path.suffix == '.yaml' or path.suffix == '.yml':
        import yaml
        with open(config_path, 'r') as f:
            config = yaml.safe_load(f)
    elif path.suffix == '.json':
        with open(config_path, 'r') as f:
            config = json.load(f)
    else:
        raise ValueError(f"Unsupported config file format: {path.suffix}")
    
    logging.info(f"Loaded configuration from {config_path}")
    return config


def export_to_geojson(track_locations: Dict[int, Dict], 
                     output_path: str,
                     properties: Optional[Dict[int, Dict]] = None) -> None:
    """
    Export track locations to GeoJSON format
    
    Args:
        track_locations: Dictionary of track locations
        output_path: Path for output GeoJSON file
        properties: Optional additional properties for each feature
    """
    features = []
    
    for track_id, location in track_locations.items():
        # Create basic properties
        feature_props = {
            'track_id': track_id,
            'accuracy': location.get('accuracy', 1.0),
            'reliability': location.get('reliability', 1.0)
        }
        
        # Add additional properties if provided
        if properties and track_id in properties:
            feature_props.update(properties[track_id])
            
        feature = {
            'type': 'Feature',
            'geometry': {
                'type': 'Point',
                'coordinates': [location['longitude'], location['latitude']]
            },
            'properties': feature_props
        }
        
        features.append(feature)
    
    geojson = {
        'type': 'FeatureCollection',
        'features': features
    }
    
    with open(output_path, 'w') as f:
        json.dump(geojson, f, indent=2)
    
    logging.info(f"Exported {len(features)} locations to GeoJSON: {output_path}")

================
File: argus_track/utils/iou.py
================
# argus_track/utils/iou.py

"""IoU (Intersection over Union) utilities for tracking"""

import numpy as np
from typing import List, Union
from numba import jit

from ..core import Track, Detection


@jit(nopython=True)
def calculate_iou_jit(bbox1: np.ndarray, bbox2: np.ndarray) -> float:
    """
    Calculate IoU between two bounding boxes (numba accelerated)
    
    Args:
        bbox1: First bbox in [x1, y1, x2, y2] format
        bbox2: Second bbox in [x1, y1, x2, y2] format
        
    Returns:
        IoU value between 0 and 1
    """
    # Get intersection coordinates
    x1 = max(bbox1[0], bbox2[0])
    y1 = max(bbox1[1], bbox2[1])
    x2 = min(bbox1[2], bbox2[2])
    y2 = min(bbox1[3], bbox2[3])
    
    # Calculate intersection area
    intersection_area = max(0, x2 - x1) * max(0, y2 - y1)
    
    # Calculate union area
    bbox1_area = (bbox1[2] - bbox1[0]) * (bbox1[3] - bbox1[1])
    bbox2_area = (bbox2[2] - bbox2[0]) * (bbox2[3] - bbox2[1])
    union_area = bbox1_area + bbox2_area - intersection_area
    
    # Avoid division by zero
    if union_area == 0:
        return 0.0
    
    return intersection_area / union_area


def calculate_iou(bbox1: np.ndarray, bbox2: np.ndarray) -> float:
    """
    Calculate IoU between two bounding boxes
    
    Args:
        bbox1: First bbox in [x1, y1, x2, y2] format
        bbox2: Second bbox in [x1, y1, x2, y2] format
        
    Returns:
        IoU value between 0 and 1
    """
    return calculate_iou_jit(bbox1, bbox2)


@jit(nopython=True)
def calculate_iou_matrix_jit(bboxes1: np.ndarray, bboxes2: np.ndarray) -> np.ndarray:
    """
    Calculate IoU matrix between two sets of bounding boxes (numba accelerated)
    
    Args:
        bboxes1: First set of bboxes in [N, 4] format
        bboxes2: Second set of bboxes in [M, 4] format
        
    Returns:
        IoU matrix of shape [N, M]
    """
    n_bbox1 = bboxes1.shape[0]
    n_bbox2 = bboxes2.shape[0]
    iou_matrix = np.zeros((n_bbox1, n_bbox2))
    
    for i in range(n_bbox1):
        for j in range(n_bbox2):
            iou_matrix[i, j] = calculate_iou_jit(bboxes1[i], bboxes2[j])
    
    return iou_matrix


def calculate_iou_matrix(tracks_or_bboxes1: Union[List[Track], np.ndarray], 
                         detections_or_bboxes2: Union[List[Detection], np.ndarray]) -> np.ndarray:
    """
    Calculate IoU matrix between tracks and detections
    
    Args:
        tracks_or_bboxes1: List of tracks or array of bboxes
        detections_or_bboxes2: List of detections or array of bboxes
        
    Returns:
        IoU matrix of shape (len(tracks_or_bboxes1), len(detections_or_bboxes2))
    """
    # Handle different input types
    if isinstance(tracks_or_bboxes1, np.ndarray):
        bboxes1 = tracks_or_bboxes1
    else:
        bboxes1 = np.array([track.to_tlbr() for track in tracks_or_bboxes1])
    
    if isinstance(detections_or_bboxes2, np.ndarray):
        bboxes2 = detections_or_bboxes2
    else:
        bboxes2 = np.array([det.tlbr for det in detections_or_bboxes2])
    
    # Calculate IoU matrix
    return calculate_iou_matrix_jit(bboxes1, bboxes2)

================
File: argus_track/utils/visualization.py
================
"""Visualization utilities"""

import cv2
import numpy as np
from typing import List, Dict, Tuple, Optional
import matplotlib.pyplot as plt
import seaborn as sns

from ..core import Track, Detection


# Color palette for different track states
TRACK_COLORS = {
    'tentative': (255, 255, 0),    # Yellow
    'confirmed': (0, 255, 0),      # Green  
    'lost': (0, 0, 255),          # Red
    'removed': (128, 128, 128)     # Gray
}


def draw_tracks(frame: np.ndarray, tracks: List[Track], 
                show_trajectory: bool = True,
                show_id: bool = True,
                show_state: bool = True) -> np.ndarray:
    """
    Draw tracks on frame
    
    Args:
        frame: Input frame
        tracks: List of tracks to draw
        show_trajectory: Whether to show track trajectories
        show_id: Whether to show track IDs
        show_state: Whether to show track states
        
    Returns:
        Frame with track visualizations
    """
    vis_frame = frame.copy()
    
    for track in tracks:
        # Get color based on state
        color = TRACK_COLORS.get(track.state, (255, 255, 255))
        
        # Draw bounding box
        x1, y1, x2, y2 = track.to_tlbr().astype(int)
        cv2.rectangle(vis_frame, (x1, y1), (x2, y2), color, 2)
        
        # Draw track information
        if show_id or show_state:
            label_parts = []
            if show_id:
                label_parts.append(f"ID: {track.track_id}")
            if show_state:
                label_parts.append(f"[{track.state}]")
            
            label = " ".join(label_parts)
            label_size, _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)
            
            # Draw label background
            cv2.rectangle(vis_frame, 
                         (x1, y1 - label_size[1] - 10),
                         (x1 + label_size[0], y1),
                         color, -1)
            
            # Draw text
            cv2.putText(vis_frame, label, (x1, y1 - 5),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)
        
        # Draw trajectory for confirmed tracks
        if show_trajectory and track.state == 'confirmed' and len(track.detections) > 1:
            points = []
            for det in track.detections[-10:]:  # Last 10 detections
                center = det.center
                points.append(center.astype(int))
            
            points = np.array(points)
            cv2.polylines(vis_frame, [points], False, color, 2)
            
            # Draw points
            for point in points:
                cv2.circle(vis_frame, tuple(point), 3, color, -1)
    
    return vis_frame


def create_track_overlay(frame: np.ndarray, tracks: List[Track],
                        alpha: float = 0.3) -> np.ndarray:
    """
    Create semi-transparent overlay with track information
    
    Args:
        frame: Input frame
        tracks: List of tracks
        alpha: Transparency level (0-1)
        
    Returns:
        Frame with overlay
    """
    overlay = np.zeros_like(frame)
    
    for track in tracks:
        if track.state != 'confirmed':
            continue
            
        # Create mask for track region
        mask = np.zeros(frame.shape[:2], dtype=np.uint8)
        x1, y1, x2, y2 = track.to_tlbr().astype(int)
        cv2.rectangle(mask, (x1, y1), (x2, y2), 255, -1)
        
        # Apply color overlay
        color = TRACK_COLORS[track.state]
        overlay[mask > 0] = color
    
    # Blend with original frame
    result = cv2.addWeighted(frame, 1 - alpha, overlay, alpha, 0)
    
    return result


def plot_track_statistics(tracks: Dict[int, Track], 
                         save_path: Optional[str] = None) -> None:
    """
    Plot tracking statistics
    
    Args:
        tracks: Dictionary of all tracks
        save_path: Optional path to save plot
    """
    fig, axes = plt.subplots(2, 2, figsize=(12, 8))
    
    # Track lengths
    track_lengths = [track.age for track in tracks.values()]
    axes[0, 0].hist(track_lengths, bins=20, edgecolor='black')
    axes[0, 0].set_title('Track Length Distribution')
    axes[0, 0].set_xlabel('Track Length (frames)')
    axes[0, 0].set_ylabel('Count')
    
    # Track states
    state_counts = {}
    for track in tracks.values():
        state = track.state
        state_counts[state] = state_counts.get(state, 0) + 1
    
    axes[0, 1].bar(state_counts.keys(), state_counts.values())
    axes[0, 1].set_title('Track State Distribution')
    axes[0, 1].set_xlabel('State')
    axes[0, 1].set_ylabel('Count')
    
    # Hits distribution
    hits_counts = [track.hits for track in tracks.values()]
    axes[1, 0].hist(hits_counts, bins=20, edgecolor='black')
    axes[1, 0].set_title('Track Hits Distribution')
    axes[1, 0].set_xlabel('Number of Hits')
    axes[1, 0].set_ylabel('Count')
    
    # Time since update for lost tracks
    lost_times = [track.time_since_update for track in tracks.values() 
                  if track.state == 'lost']
    if lost_times:
        axes[1, 1].hist(lost_times, bins=15, edgecolor='black')
        axes[1, 1].set_title('Time Since Update (Lost Tracks)')
        axes[1, 1].set_xlabel('Frames Since Update')
        axes[1, 1].set_ylabel('Count')
    else:
        axes[1, 1].text(0.5, 0.5, 'No Lost Tracks', 
                       ha='center', va='center', fontsize=14)
        axes[1, 1].set_xticks([])
        axes[1, 1].set_yticks([])
    
    plt.tight_layout()
    
    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
    else:
        plt.show()


def draw_detection(frame: np.ndarray, detection: Detection, 
                  color: Tuple[int, int, int] = (0, 255, 0),
                  thickness: int = 2) -> np.ndarray:
    """
    Draw single detection on frame
    
    Args:
        frame: Input frame
        detection: Detection to draw
        color: Color for drawing
        thickness: Line thickness
        
    Returns:
        Frame with detection drawn
    """
    result = frame.copy()
    x1, y1, x2, y2 = detection.tlbr.astype(int)
    
    # Draw bounding box
    cv2.rectangle(result, (x1, y1), (x2, y2), color, thickness)
    
    # Draw score
    label = f"{detection.score:.2f}"
    label_size, _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.4, 1)
    
    cv2.rectangle(result,
                 (x1, y1 - label_size[1] - 8),
                 (x1 + label_size[0], y1),
                 color, -1)
    
    cv2.putText(result, label, (x1, y1 - 4),
               cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)
    
    return result


def create_tracking_summary(tracks: Dict[int, Track],
                           frame_width: int = 1920,
                           frame_height: int = 1080) -> np.ndarray:
    """
    Create summary visualization of all tracks
    
    Args:
        tracks: Dictionary of all tracks
        frame_width: Width of output frame
        frame_height: Height of output frame
        
    Returns:
        Summary visualization frame
    """
    # Create blank canvas
    canvas = np.ones((frame_height, frame_width, 3), dtype=np.uint8) * 255
    
    # Draw track trajectories
    for track in tracks.values():
        if len(track.detections) < 2:
            continue
            
        # Get trajectory points
        points = np.array([det.center for det in track.detections])
        
        # Scale to fit canvas
        points[:, 0] = points[:, 0] / points[:, 0].max() * (frame_width - 100) + 50
        points[:, 1] = points[:, 1] / points[:, 1].max() * (frame_height - 100) + 50
        
        # Choose color based on track state
        color = TRACK_COLORS.get(track.state, (0, 0, 0))
        
        # Draw trajectory
        for i in range(1, len(points)):
            cv2.line(canvas, 
                    tuple(points[i-1].astype(int)),
                    tuple(points[i].astype(int)),
                    color, 2)
        
        # Draw track ID at end
        cv2.putText(canvas, f"ID: {track.track_id}", 
                   tuple(points[-1].astype(int)),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)
    
    # Add legend
    y_offset = 30
    for state, color in TRACK_COLORS.items():
        cv2.rectangle(canvas, (20, y_offset), (40, y_offset + 20), color, -1)
        cv2.putText(canvas, state, (50, y_offset + 15),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 1)
        y_offset += 30
    
    return canvas

================
File: argus_track/__init__.py
================
"""
ByteTrack Light Post Tracking System
====================================

A specialized implementation of ByteTrack for tracking light posts in video sequences
with GPS integration for 3D position estimation.

Key Features:
- Optimized for static/slow-moving objects
- GPS data integration for geolocation
- Modular architecture with clear separation of concerns
- Comprehensive logging and error handling
- Type hints and documentation throughout

Author: Light Post Tracking Team
Date: 2025
License: MIT
"""

from argus_track.__version__ import __version__
from argus_track.config import TrackerConfig
from argus_track.core import Detection, Track, GPSData
from argus_track.trackers import ByteTrack, LightPostTracker
from argus_track.detectors import YOLODetector, ObjectDetector
from argus_track.exceptions import (
    ArgusTrackError, 
    DetectorError, 
    TrackerError,
    ConfigurationError,
    GPSError,
    VideoError
)
from argus_track.analysis import StaticObjectAnalyzer
__all__ = [
    "__version__",
    "TrackerConfig",
    "Detection",
    "Track",
    "GPSData",
    "ByteTrack",
    "LightPostTracker",
    "YOLODetector",
    "ObjectDetector",
]

================
File: argus_track/__version__.py
================
"""Version information for ByteTrack Light Post Tracking System"""

__version__ = "1.0.0"
__author__ = "Light Post Tracking Team"
__email__ = "joaquin.olivera@gmial.com"
__description__ = "ByteTrack implementation optimized for light post tracking with GPS integration"

================
File: argus_track/config.py
================
"""Configuration classes for ByteTrack Light Post Tracking System"""

from dataclasses import dataclass
from typing import Optional
import yaml
import json
from pathlib import Path


@dataclass
class TrackerConfig:
    """Configuration for ByteTrack light post tracker"""
    track_thresh: float = 0.5          # Minimum detection confidence
    match_thresh: float = 0.8          # Minimum IoU for matching
    track_buffer: int = 50             # Frames to keep lost tracks
    min_box_area: float = 100.0        # Minimum detection area
    static_threshold: float = 2.0      # Pixel movement threshold for static detection
    min_static_frames: int = 5         # Frames needed to confirm static object
    
    @classmethod
    def from_yaml(cls, yaml_path: str) -> 'TrackerConfig':
        """Load configuration from YAML file"""
        with open(yaml_path, 'r') as f:
            config_dict = yaml.safe_load(f)
        return cls(**config_dict)
    
    @classmethod
    def from_json(cls, json_path: str) -> 'TrackerConfig':
        """Load configuration from JSON file"""
        with open(json_path, 'r') as f:
            config_dict = json.load(f)
        return cls(**config_dict)
    
    def save_yaml(self, output_path: str) -> None:
        """Save configuration to YAML file"""
        with open(output_path, 'w') as f:
            yaml.dump(self.__dict__, f, default_flow_style=False)
    
    def save_json(self, output_path: str) -> None:
        """Save configuration to JSON file"""
        with open(output_path, 'w') as f:
            json.dump(self.__dict__, f, indent=2)


@dataclass
class DetectorConfig:
    """Configuration for object detectors"""
    model_path: str
    config_path: str
    target_classes: Optional[list] = None
    confidence_threshold: float = 0.5
    nms_threshold: float = 0.4
    

@dataclass
class CameraConfig:
    """Camera calibration parameters"""
    camera_matrix: list
    distortion_coeffs: list
    image_width: int
    image_height: int
    
    @classmethod
    def from_file(cls, calibration_path: str) -> 'CameraConfig':
        """Load camera configuration from file"""
        with open(calibration_path, 'r') as f:
            data = json.load(f)
        return cls(**data)

================
File: argus_track/exceptions.py
================
"""Custom exceptions for Argus Track"""


class ArgusTrackError(Exception):
    """Base exception for Argus Track"""
    pass


class DetectorError(ArgusTrackError):
    """Raised when detector operations fail"""
    pass


class TrackerError(ArgusTrackError):
    """Raised when tracker operations fail"""
    pass


class ConfigurationError(ArgusTrackError):
    """Raised when configuration is invalid"""
    pass


class GPSError(ArgusTrackError):
    """Raised when GPS operations fail"""
    pass


class VideoError(ArgusTrackError):
    """Raised when video processing fails"""
    pass

================
File: argus_track/main.py
================
"""Main entry point for ByteTrack Light Post Tracking System"""

import argparse
import logging
from pathlib import Path
from typing import Optional

from argus_track import (
    TrackerConfig,
    LightPostTracker,
    YOLODetector,
    MockDetector,
    __version__
)
from argus_track.utils import setup_logging, load_gps_data


def create_detector(detector_type: str, config_path: Optional[str] = None):
    """Create detector based on type"""
    if detector_type == 'yolo' and config_path:
        # Parse YOLO config path to get weights and config
        config_dir = Path(config_path).parent
        weights_path = config_dir / 'yolov4.weights'
        cfg_path = config_dir / 'yolov4.cfg'
        
        if not weights_path.exists() or not cfg_path.exists():
            logging.warning("YOLO files not found, using mock detector")
            return MockDetector(target_classes=['light_post', 'street_light'])
        
        return YOLODetector(
            model_path=str(weights_path),
            config_path=str(cfg_path),
            target_classes=['light_post', 'street_light', 'pole']
        )
    else:
        return MockDetector(target_classes=['light_post', 'street_light'])


def main():
    """Main function demonstrating the tracker usage"""
    parser = argparse.ArgumentParser(
        description=f"ByteTrack Light Post Tracking System v{__version__}"
    )
    
    # Required arguments
    parser.add_argument('input_video', type=str, 
                       help='Path to input video file')
    
    # Optional arguments
    parser.add_argument('--output', type=str, default=None,
                       help='Path for output video (optional)')
    parser.add_argument('--config', type=str, default=None,
                       help='Path to configuration file')
    parser.add_argument('--gps', type=str, default=None,
                       help='Path to GPS data CSV file')
    parser.add_argument('--detector', type=str, default='mock',
                       choices=['yolo', 'mock'],
                       help='Detector type to use')
    parser.add_argument('--log-file', type=str, default=None,
                       help='Path to log file')
    parser.add_argument('--verbose', action='store_true',
                       help='Enable verbose logging')
    parser.add_argument('--no-save', action='store_true',
                       help='Do not save tracking results')
    
    # Tracking parameters
    parser.add_argument('--track-thresh', type=float, default=0.5,
                       help='Detection confidence threshold')
    parser.add_argument('--match-thresh', type=float, default=0.8,
                       help='IoU threshold for matching')
    parser.add_argument('--track-buffer', type=int, default=50,
                       help='Number of frames to keep lost tracks')
    
    args = parser.parse_args()
    
    # Setup logging
    log_level = logging.DEBUG if args.verbose else logging.INFO
    setup_logging(log_file=args.log_file, level=log_level)
    logger = logging.getLogger(__name__)
    
    logger.info(f"ByteTrack Light Post Tracking System v{__version__}")
    
    # Load configuration
    if args.config:
        config = TrackerConfig.from_yaml(args.config)
    else:
        config = TrackerConfig(
            track_thresh=args.track_thresh,
            match_thresh=args.match_thresh,
            track_buffer=args.track_buffer
        )
    
    # Initialize detector
    try:
        detector = create_detector(args.detector, args.config)
        logger.info(f"Initialized {args.detector} detector")
    except Exception as e:
        logger.error(f"Failed to initialize detector: {e}")
        return 1
    
    # Initialize tracker
    tracker = LightPostTracker(
        config=config,
        detector=detector
    )
    
    # Load GPS data if provided
    gps_data = None
    if args.gps:
        try:
            gps_data = load_gps_data(args.gps)
            logger.info(f"Loaded {len(gps_data)} GPS data points")
        except Exception as e:
            logger.error(f"Failed to load GPS data: {e}")
    
    # Process video
    input_path = Path(args.input_video)
    if not input_path.exists():
        logger.error(f"Input video not found: {input_path}")
        return 1
    
    try:
        tracks = tracker.process_video(
            video_path=str(input_path),
            gps_data=gps_data,
            output_path=args.output,
            save_results=not args.no_save
        )
        
        # Print statistics
        stats = tracker.get_track_statistics()
        logger.info("Tracking Statistics:")
        for key, value in stats.items():
            logger.info(f"  {key}: {value}")
        
        # Analyze static objects
        static_analysis = tracker.analyze_static_objects()
        static_count = sum(1 for is_static in static_analysis.values() if is_static)
        logger.info(f"Identified {static_count} static objects out of {len(static_analysis)}")
        
        logger.info("Processing complete!")
        return 0
        
    except Exception as e:
        logger.error(f"Error during processing: {e}")
        return 1


if __name__ == "__main__":
    exit(main())

================
File: argus_track/requirements.txt
================
# argus_track/requirements.txt

# Core dependencies
numpy>=1.19.0
scipy>=1.5.0
opencv-python>=4.5.0
filterpy>=1.4.5
numba>=0.53.0  # For JIT compilation

# Optional optimizations
lap>=0.4.0  # Faster Hungarian algorithm

# Visualization
matplotlib>=3.3.0
seaborn>=0.11.0

# Development dependencies
pytest>=6.0.0
pytest-benchmark>=3.4.0
black>=21.0
flake8>=3.9.0
mypy>=0.910

# Documentation
sphinx>=4.0.0
sphinx-rtd-theme>=0.5.0

# GPS support
pyproj>=3.0.0  # For GPS coordinate transformations
scikit-learn>=0.24.0  # For clustering in static analysis
pynvml>=11.0.0  # Optional: For GPU monitoring

# GPS visualization
folium>=0.12.0  # For interactive maps
geojson>=2.5.0  # For GeoJSON export

================
File: docs/HOW_IT_WORKS.md
================
# Argus Track: ByteTrack with Geolocation

This document provides a detailed explanation of the ByteTrack implementation for light post tracking with geolocation capabilities.

## Table of Contents

1. [Overview](#overview)
2. [Core Components](#core-components)
3. [Workflow](#workflow)
4. [Algorithm Details](#algorithm-details)
5. [Geolocation System](#geolocation-system)
6. [Performance Optimizations](#performance-optimizations)

## Overview

Argus Track is a specialized implementation of ByteTrack optimized for tracking static infrastructure elements such as light posts, traffic signals, and poles in video sequences. It integrates GPS data to provide real-world geographic coordinates for tracked objects.

Key features include:
- Optimized multi-object tracking using a two-stage association algorithm
- Specialized Kalman filtering for static/slow-moving objects
- GPS integration for real-world position estimation
- Static object analysis and identification
- Geolocation estimation with reliability metrics
- Export to GeoJSON for mapping integration

## Core Components

### 1. Data Structures

- **Detection**: Represents a single object detection in a frame
  - Bounding box (x1, y1, x2, y2)
  - Confidence score
  - Class ID
  - Frame ID

- **Track**: Represents a tracked object through multiple frames
  - Track ID
  - State (tentative, confirmed, lost, removed)
  - Detection history
  - Kalman filter
  - Age, hits, time since update

- **GPSData**: Contains GPS information for a specific timestamp
  - Timestamp
  - Latitude, longitude, altitude
  - Heading, accuracy

- **GeoLocation**: Represents an estimated geographic location
  - Latitude, longitude
  - Accuracy (in meters)
  - Reliability score (0-1)
  - Timestamp

### 2. Key Classes

- **ByteTrack**: Core tracking algorithm implementation
  - Maintains track lifecycle
  - Handles two-stage association
  - Manages track states

- **LightPostTracker**: High-level tracking system
  - Orchestrates detection, tracking, and GPS integration
  - Analyzes static objects
  - Estimates geographic locations

- **KalmanBoxTracker**: Motion prediction
  - Predicts object movement using constant velocity model
  - Optimized for static/slow-moving objects

- **CoordinateTransformer**: Geographic utilities
  - Converts between GPS and local coordinates
  - Calculates distances between geographic points

## Workflow

The complete tracking workflow follows these steps:

1. **Initialization**:
   - Load configuration parameters
   - Initialize detector (YOLO or Mock)
   - Create ByteTrack instance
   - Set up GPS processing

2. **Video Processing**:
   - Read video frame-by-frame
   - For each frame:
     - Detect objects
     - Update tracker with detections
     - Associate GPS data with active tracks
     - Visualize results (optional)

3. **Post-Processing**:
   - Analyze tracks to identify static objects
   - Filter and estimate locations for static objects
   - Calculate reliability metrics for locations
   - Export results (JSON, GeoJSON, CSV)

## Algorithm Details

### 1. ByteTrack Tracking

ByteTrack uses a two-stage association strategy to maintain robust tracking:

#### First Association Stage:
- Match high-confidence detections (score  threshold) with existing tracks
- Use IoU (Intersection over Union) as the similarity metric
- Apply Hungarian algorithm to find optimal matches
- Update matched tracks with new detections

#### Second Association Stage:
- Take unmatched tracks from first stage
- Match with low-confidence detections (score < threshold)
- Use lower IoU threshold for matching
- This recovers tracks during partial occlusions or poor detection conditions

#### Track Lifecycle:
- **Tentative**: New tracks (< 3 detections)
- **Confirmed**: Established tracks ( 3 detections)
- **Lost**: Tracks with no matching detections
- **Removed**: Lost tracks exceeding the buffer time

### 2. Kalman Filtering

Specialized Kalman filtering for static objects:

- **State Vector**: [x, y, w, h, vx, vy, vw, vh]
  - x, y: center position
  - w, h: width, height
  - vx, vy, vw, vh: velocities

- **Optimizations for Static Objects**:
  - Reduced process noise for velocity components (0.01 multiplier)
  - Higher initial uncertainty for velocities (1000 multiplier)
  - Lower uncertainty for position components (10 multiplier)

- **Numerical Stability**:
  - Monitors covariance matrix trace
  - Resets if values grow too large

### 3. Static Object Analysis

Identifying which tracked objects are static infrastructure:

- Calculate position variance over recent frames
- Measure standard deviation of center positions
- Compare against static_threshold parameter
- Require minimum number of consecutive frames (min_static_frames)
- Classify as static if movement is below threshold

## Geolocation System

### 1. GPS Association

- GPS data points are timestamped and synchronized with video frames
- For each processed frame, the corresponding GPS data is attached to all active tracks
- This builds up a history of GPS points for each track
- If GPS data is not perfectly aligned with frames, interpolation is used

### 2. Location Estimation

For static objects (like light posts), we estimate their geographic location:

1. **Filtering**:
   - Collect all GPS points associated with the track
   - Remove outliers using DBSCAN clustering
   - Keep points in the largest cluster (most consistent readings)

2. **Averaging**:
   - Calculate weighted average based on GPS accuracy
   - Points with higher accuracy get higher weight
   - This produces a single lat/lon estimate

3. **Reliability Calculation**:
   - Compute standard deviation of distances from average position
   - Calculate reliability score (inversely related to std dev)
   - Higher consistency = higher reliability
   - Reliability ranges from 0 (unreliable) to 1 (highly reliable)

### 3. Output Formats

- **GeoJSON**: For mapping applications
  - Each static object becomes a Point feature
  - Properties include track_id, reliability, accuracy

- **JSON**: Complete tracking results
  - Track trajectories
  - GPS histories
  - Estimated locations

- **CSV**: Simplified location data
  - track_id, latitude, longitude, reliability

## Performance Optimizations

### 1. Vectorized Operations

- **Batch Kalman Prediction**: Process multiple tracks simultaneously
- **Numba-accelerated IoU**: JIT compilation for faster intersection calculations
- **Vectorized IoU Matrix**: Efficiently compute all track-detection similarities

### 2. Memory Management

- Limited detection history storage (last N detections)
- Track removal after buffer expiration
- Efficient NumPy array operations

### 3. Error Handling

- Robust GPS data validation
- Fallback strategies for missing GPS data
- Outlier filtering to remove noise

### 4. Duplicate Track Management

- Identify tracks that likely represent the same object
- Merge duplicate tracks based on proximity
- Preserve the track with more consistent history

================
File: docs/library_doc.md
================
## Proposed Library Structure

```
ArgusTrack/
 README.md
 setup.py
 requirements.txt
 tests/
    __init__.py
    test_core.py
    test_detectors.py
    test_filters.py
    test_tracker.py
    test_utils.py
 examples/
    basic_tracking.py
    video_tracking_with_gps.py
    config_examples/
        default_config.yaml
 docs/
    conf.py
    index.md
    api/
       core.md
       detectors.md
       trackers.md
    tutorials/
        getting_started.md
        advanced_usage.md
 argus_track/
     __init__.py
     __version__.py
     config.py
     core/
        __init__.py
        track.py
        detection.py
        gps.py
     filters/
        __init__.py
        kalman.py
     detectors/
        __init__.py
        base.py
        yolo.py
        mock.py
     trackers/
        __init__.py
        bytetrack.py
        lightpost_tracker.py
     utils/
        __init__.py
        iou.py
        visualization.py
        io.py
     main.py
```

## Module Breakdown

### Core Data Classes (`core/`)
- `track.py`: Track class
- `detection.py`: Detection class
- `gps.py`: GPSData class

### Configuration (`config.py`)
- TrackerConfig and other configuration classes

### Filters (`filters/`)
- `kalman.py`: KalmanBoxTracker implementation

### Detectors (`detectors/`)
- `base.py`: ObjectDetector protocol/base class
- `yolo.py`: YOLODetector implementation
- `mock.py`: MockDetector for testing

### Trackers (`trackers/`)
- `bytetrack.py`: ByteTrack core implementation
- `lightpost_tracker.py`: LightPostTracker with GPS integration

### Utilities (`utils/`)
- `iou.py`: IoU calculation utilities
- `visualization.py`: Visualization functions
- `io.py`: I/O operations, GPS data loading

### Main Entry Point (`main.py`)
- Command-line interface and main execution logic

================
File: docs/USAGE_GUIDE.md
================
# Argus Track: Usage Guide

This document provides detailed instructions for using Argus Track, our ByteTrack implementation optimized for light post tracking with geolocation capabilities.

## Table of Contents

1. [Installation](#installation)
2. [Basic Usage](#basic-usage)
3. [Command Line Interface](#command-line-interface)
4. [Working with GPS Data](#working-with-gps-data)
5. [Configuration](#configuration)
6. [Output Files](#output-files)
7. [Visualizing Results](#visualizing-results)
8. [API Usage](#api-usage)
9. [Troubleshooting](#troubleshooting)

## Installation

### Prerequisites

- Python 3.8 or newer
- OpenCV with Python bindings
- NumPy, SciPy
- Recommended: CUDA-compatible GPU for YOLO detection

### From Source

```bash
# Clone the repository
git clone https://github.com/Bell-South/ArgusTrack.git
cd ArgusTrack

# Install dependencies
pip install -r argus_track/requirements.txt

# Install the package in development mode
pip install -e .
```

### Using pip

```bash
pip install argus-track
```

## Basic Usage

### Quick Start Example

Here's a simple example to get started:

```bash
# Create sample data (if you don't have your own)
# First, create a sample video file
python -c "import cv2, numpy as np; video = cv2.VideoWriter('sample.mp4', cv2.VideoWriter_fourcc(*'mp4v'), 30, (640, 480)); [video.write(np.zeros((480, 640, 3), dtype=np.uint8)) for _ in range(100)]; video.release()"

# Create sample GPS data
echo "timestamp,latitude,longitude,altitude,heading,accuracy
1000.0,40.7128,-74.0060,10.0,0.0,1.0
1033.0,40.7129,-74.0061,10.0,0.0,1.0
1066.0,40.7128,-74.0062,10.0,0.0,1.0
1100.0,40.7127,-74.0061,10.0,0.0,1.0
1133.0,40.7128,-74.0060,10.0,0.0,1.0" > sample_gps.csv

# Run geolocation tracking
python examples/geolocation_tracking.py sample.mp4 sample_gps.csv --detector mock
```

This will produce:
- A tracking results JSON file (`sample.json`)
- A GeoJSON file with locations (`sample.geojson`)
- Terminal output with location estimates and statistics

## Command Line Interface

The package provides several command-line tools:

### Geolocation Tracking

Track objects and estimate their geographic locations:

```bash
python examples/geolocation_tracking.py VIDEO_PATH GPS_PATH [OPTIONS]
```

Required arguments:
- `VIDEO_PATH`: Path to input video file
- `GPS_PATH`: Path to GPS data in CSV format

Options:
- `--output PATH`: Path for output video with visualizations
- `--geojson PATH`: Path for GeoJSON output (default: VIDEO_PATH.geojson)
- `--config PATH`: Path to configuration file
- `--detector {yolo,mock}`: Detector type to use (default: mock)
- `--verbose`: Enable verbose logging

### Basic Tracking

Run tracking without GPS integration:

```bash
python examples/basic_tracking.py VIDEO_PATH [--output PATH] [--config PATH]
```

### Main CLI Tool

General-purpose command-line interface:

```bash
python -m argus_track VIDEO_PATH [OPTIONS]
```

Options:
- `--output PATH`: Path for output video
- `--config PATH`: Path to configuration file
- `--gps PATH`: Path to GPS data CSV file
- `--detector {yolo,mock}`: Detector to use
- `--log-file PATH`: Path to log file
- `--verbose`: Enable verbose logging
- `--no-save`: Do not save tracking results

## Working with GPS Data

### GPS Data Format

The required GPS data format is a CSV file with the following columns:

```
timestamp,latitude,longitude,altitude,heading,accuracy
```

Example:
```
timestamp,latitude,longitude,altitude,heading,accuracy
1623456789.0,40.7128,-74.0060,10.5,45.0,1.0
1623456790.0,40.7129,-74.0061,10.6,45.2,1.0
```

Fields:
- `timestamp`: Time in seconds (can be Unix timestamp or relative time)
- `latitude`, `longitude`: Geographic coordinates (decimal degrees)
- `altitude`: Height above sea level (meters, optional)
- `heading`: Direction in degrees (0-360, optional)
- `accuracy`: GPS accuracy in meters (optional, default 1.0)

### Synchronizing GPS with Video

For best results, the timestamps in your GPS data should match the video frames. If timestamps don't align perfectly, the system will interpolate GPS data to match frame timestamps.

```python
# Sample code to create synchronized GPS data
from argus_track.utils.gps_utils import sync_gps_with_frames
from argus_track.utils.io import load_gps_data

# Load original GPS data
gps_data = load_gps_data("original_gps.csv")

# Synchronize with video frame rate
video_fps = 30.0
start_timestamp = gps_data[0].timestamp
synchronized_gps = sync_gps_with_frames(gps_data, video_fps, start_timestamp)
```

## Configuration

### Configuration File

Create a YAML or JSON file with configuration parameters:

```yaml
# tracker_config.yaml
track_thresh: 0.5          # Minimum detection confidence
match_thresh: 0.8          # Minimum IoU for matching
track_buffer: 50           # Frames to keep lost tracks
min_box_area: 100.0        # Minimum detection area
static_threshold: 2.0      # Pixel movement threshold
min_static_frames: 5       # Frames needed to confirm static object
```

### Configuration Parameters

Key parameters for tuning:

- `track_thresh`: Minimum detection confidence to create/update tracks (0-1)
- `match_thresh`: Minimum IoU threshold for first association stage (0-1)
- `track_buffer`: How many frames to keep lost tracks before removal
- `static_threshold`: Maximum pixel movement to consider an object static
- `min_static_frames`: Number of frames required to classify as static

## Output Files

The system produces several output files:

### Tracking Results (JSON)

Contains complete tracking data:
- Track trajectories
- Track states and statistics
- GPS associations
- Location estimates

```json
{
  "metadata": {
    "total_frames": 100,
    "fps": 30.0,
    "width": 1280,
    "height": 720,
    "config": {
      "track_thresh": 0.5,
      "match_thresh": 0.8,
      "track_buffer": 50
    }
  },
  "tracks": {
    "0": [
      {"frame": 0, "bbox": [100, 100, 200, 200], "score": 0.9, "state": "tentative", "hits": 1},
      {"frame": 1, "bbox": [102, 102, 202, 202], "score": 0.92, "state": "tentative", "hits": 2}
    ]
  },
  "track_locations": {
    "0": {
      "latitude": 40.7128,
      "longitude": -74.0060,
      "accuracy": 1.0,
      "reliability": 0.95
    }
  }
}
```

### GeoJSON

Contains location data in GeoJSON format for mapping:

```json
{
  "type": "FeatureCollection",
  "features": [
    {
      "type": "Feature",
      "geometry": {
        "type": "Point",
        "coordinates": [-74.0060, 40.7128]
      },
      "properties": {
        "track_id": 0,
        "reliability": 0.95,
        "accuracy": 1.0
      }
    }
  ]
}
```

### Output Video

Visualizes tracking results with:
- Bounding boxes
- Track IDs
- Track states (color-coded)
- Trajectories (for confirmed tracks)

## Visualizing Results

### Mapping Locations

You can visualize the GeoJSON output using various GIS tools:

- **Online Tools**: [geojson.io](https://geojson.io), [Mapbox](https://mapbox.com)
- **Python Libraries**: Folium, Plotly, GeoPandas

Example with Folium:

```python
import folium
import json

# Load GeoJSON file
with open('output.geojson', 'r') as f:
    data = json.load(f)

# Create map
m = folium.Map()

# Add GeoJSON data
folium.GeoJson(
    data,
    name='Light Posts',
    tooltip=folium.GeoJsonTooltip(fields=['track_id', 'reliability']),
    style_function=lambda x: {
        'radius': 8,
        'fillColor': 'red' if x['properties']['reliability'] > 0.8 else 'orange',
        'color': 'black',
        'weight': 1,
        'opacity': 1,
        'fillOpacity': 0.8
    }
).add_to(m)

# Save map
m.save('map.html')
```

### Visualization Utilities

The package includes visualization utilities:

```python
from argus_track.utils.visualization import draw_tracks, plot_track_statistics

# Draw tracks on frame
vis_frame = draw_tracks(frame, tracks, show_trajectory=True, show_id=True)

# Plot tracking statistics
plot_track_statistics(tracks, save_path='stats.png')
```

## API Usage

### Core Usage Pattern

```python
from argus_track import (
    TrackerConfig,
    LightPostTracker,
    MockDetector
)
from argus_track.utils.io import load_gps_data

# Create configuration
config = TrackerConfig(
    track_thresh=0.5,
    match_thresh=0.8,
    track_buffer=50,
    static_threshold=2.0,
    min_static_frames=5
)

# Initialize detector and tracker
detector = MockDetector(target_classes=['light_post'])
tracker = LightPostTracker(config, detector)

# Load GPS data
gps_data = load_gps_data('gps_data.csv')

# Process video
tracks = tracker.process_video(
    video_path='input_video.mp4',
    gps_data=gps_data,
    output_path='output_video.mp4',
    save_results=True
)

# Analyze static objects
static_objects = tracker.analyze_static_objects()
print(f"Found {sum(static_objects.values())} static objects")

# Get location estimates
locations = tracker.get_static_locations()
for track_id, location in locations.items():
    print(f"Track {track_id}: ({location.latitude}, {location.longitude}), "
          f"reliability: {location.reliability:.2f}")

# Export to GeoJSON
tracker.export_locations_to_geojson('output.geojson')
```

### Processing Individual Frames

For more control, you can process frames individually:

```python
import cv2
from argus_track import (
    TrackerConfig,
    LightPostTracker, 
    MockDetector,
    GPSData
)

# Initialize tracker
config = TrackerConfig()
detector = MockDetector(target_classes=['light_post'])
tracker = LightPostTracker(config, detector)

# Open video
cap = cv2.VideoCapture('input_video.mp4')

# Process frames
frame_idx = 0
while True:
    ret, frame = cap.read()
    if not ret:
        break
    
    # Create GPS data for this frame
    gps = GPSData(
        timestamp=1000.0 + frame_idx * 33.3,  # Assuming 30fps
        latitude=40.7128,
        longitude=-74.0060,
        altitude=10.0,
        heading=0.0
    )
    
    # Process frame
    tracks = tracker.process_frame(frame, frame_idx, gps)
    
    # Visualize
    vis_frame = draw_tracks(frame, tracks)
    cv2.imshow('Tracking', vis_frame)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break
    
    frame_idx += 1

# Cleanup
cap.release()
cv2.destroyAllWindows()

# Get location estimates
locations = tracker.get_static_locations()
```

## Troubleshooting

### Common Issues

1. **No Detections**:
   - Check if detector is configured correctly
   - Ensure target_classes includes relevant classes (e.g., 'light_post')
   - Try lowering confidence_threshold

2. **Poor Tracking**:
   - Adjust track_thresh and match_thresh parameters
   - Increase track_buffer for longer persistence
   - Check for proper frame rate processing

3. **Inaccurate Locations**:
   - Verify GPS data quality and timestamps
   - Adjust static_threshold for proper static object detection
   - Increase min_static_frames for more robust classification

4. **YOLO Detector Issues**:
   - Check if model and config files exist
   - Ensure OpenCV compilation with DNN support
   - Consider trying with mock detector first

### Logging

Enable verbose logging for debugging:

```bash
python examples/geolocation_tracking.py video.mp4 gps.csv --verbose
```

Or in code:

```python
import logging
logging.basicConfig(level=logging.DEBUG)
```

### Performance Considerations

- For large videos, consider processing in segments
- YOLO detection is much faster with GPU support
- Reduce resolution if processing is too slow
- Batch processing can be more efficient for multiple videos

================
File: examples/config_examples/default_config.yaml
================
# Default tracker configuration
track_thresh: 0.5          # Minimum detection confidence for tracking
match_thresh: 0.8          # Minimum IoU for track-detection matching
track_buffer: 50           # Frames to keep lost tracks before removal
min_box_area: 100.0        # Minimum bounding box area to consider
static_threshold: 2.0      # Maximum pixel movement for static classification
min_static_frames: 5       # Minimum frames to confirm static object

# Detector configuration
detector:
  confidence_threshold: 0.5
  nms_threshold: 0.4
  target_classes:
    - light_post
    - street_light
    - pole
    - traffic_light

# Camera calibration (optional)
camera:
  calibration_file: null   # Path to camera calibration JSON
  
# Performance settings
performance:
  max_track_age: 100       # Maximum track age in frames
  min_track_length: 3      # Minimum track length to save
  gpu_backend: cpu         # cpu, cuda, or opencl

================
File: examples/basic_tracking.py
================
"""Basic tracking example"""

from argus_track import (
    TrackerConfig,
    LightPostTracker,
    MockDetector
)


def main():
    """Run basic tracking on a video file"""
    
    # Create configuration
    config = TrackerConfig(
        track_thresh=0.5,
        match_thresh=0.8,
        track_buffer=50,
        min_box_area=100.0
    )
    
    # Initialize mock detector for testing
    detector = MockDetector(target_classes=['light_post', 'street_light'])
    
    # Create tracker
    tracker = LightPostTracker(config, detector)
    
    # Process video
    tracks = tracker.process_video(
        video_path='input/test_video.mp4',
        output_path='output/tracked_video.mp4',
        save_results=True
    )
    
    # Print statistics
    stats = tracker.get_track_statistics()
    print(f"Tracked {stats['total_tracks']} objects")
    print(f"Active tracks: {stats['active_tracks']}")
    print(f"Static objects: {stats['static_objects']}")
    
    # Analyze static objects
    static_analysis = tracker.analyze_static_objects()
    static_count = sum(1 for is_static in static_analysis.values() if is_static)
    print(f"Identified {static_count} static light posts")


if __name__ == "__main__":
    main()

================
File: examples/geolocation_tracking.py
================
# examples/geolocation_tracking.py

"""Example demonstrating light post tracking with geolocation"""

import argparse
import logging
import cv2
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path

from argus_track import (
    TrackerConfig,
    LightPostTracker,
    MockDetector,
    YOLODetector
)
from argus_track.utils.io import load_gps_data, export_to_geojson
from argus_track.utils.gps_utils import GeoLocation


def main():
    """Run light post tracking with geolocation"""
    parser = argparse.ArgumentParser(description="Light Post Tracking with Geolocation")
    
    # Required arguments
    parser.add_argument("video_path", type=str, help="Path to input video")
    parser.add_argument("gps_path", type=str, help="Path to GPS data CSV")
    
    # Optional arguments
    parser.add_argument("--output", type=str, default=None, help="Path for output video")
    parser.add_argument("--geojson", type=str, default=None, help="Path for GeoJSON output")
    parser.add_argument("--config", type=str, default=None, help="Path to config file")
    parser.add_argument("--detector", type=str, choices=["yolo", "mock"], default="mock",
                       help="Detector type to use")
    parser.add_argument("--verbose", action="store_true", help="Enable verbose logging")
    
    args = parser.parse_args()
    
    # Setup logging
    log_level = logging.DEBUG if args.verbose else logging.INFO
    logging.basicConfig(
        level=log_level,
        format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
    )
    
    # Load configuration
    if args.config:
        from argus_track.utils.io import load_config_from_file
        config_dict = load_config_from_file(args.config)
        config = TrackerConfig(**config_dict)
    else:
        config = TrackerConfig(
            track_thresh=0.5,
            match_thresh=0.8,
            track_buffer=50,
            static_threshold=2.0,
            min_static_frames=5
        )
    
    # Initialize detector
    if args.detector == "yolo":
        try:
            detector = YOLODetector(
                model_path="models/yolov4.weights",
                config_path="models/yolov4.cfg",
                target_classes=["light_post", "street_light", "pole"]
            )
        except Exception as e:
            logging.error(f"Failed to initialize YOLO detector: {e}")
            logging.info("Falling back to mock detector")
            detector = MockDetector(target_classes=["light_post"])
    else:
        detector = MockDetector(target_classes=["light_post"])
    
    # Load GPS data
    try:
        gps_data = load_gps_data(args.gps_path)
        logging.info(f"Loaded {len(gps_data)} GPS data points")
    except Exception as e:
        logging.error(f"Failed to load GPS data: {e}")
        return 1
    
    # Initialize tracker
    tracker = LightPostTracker(config, detector)
    
    # Process video
    logging.info(f"Processing video: {args.video_path}")
    try:
        tracks = tracker.process_video(
            video_path=args.video_path,
            gps_data=gps_data,
            output_path=args.output,
            save_results=True
        )
    except Exception as e:
        logging.error(f"Error processing video: {e}")
        return 1
    
    # Analyze static objects and locations
    static_objects = tracker.analyze_static_objects()
    static_count = sum(1 for is_static in static_objects.values() if is_static)
    logging.info(f"Identified {static_count} static objects")
    
    # Get location estimates
    locations = tracker.get_static_locations()
    logging.info(f"Estimated locations for {len(locations)} static objects")
    
    # Export locations to GeoJSON if requested
    if args.geojson:
        geojson_path = args.geojson
    else:
        geojson_path = Path(args.video_path).with_suffix('.geojson')
    
    tracker.export_locations_to_geojson(geojson_path)
    logging.info(f"Exported locations to GeoJSON: {geojson_path}")
    
    # Print location results
    print("\nEstimated Light Post Locations:")
    print("------------------------------")
    for track_id, location in locations.items():
        print(f"Track {track_id}: "
              f"({location.latitude:.6f}, {location.longitude:.6f}) "
              f"Reliability: {location.reliability:.2f}")
    
    # Display stats
    stats = tracker.get_track_statistics()
    for key, value in stats.items():
        print(f"{key}: {value}")
    
    return 0


if __name__ == "__main__":
    exit(main())

================
File: examples/video_tracking_with_gps.py
================
"""Video tracking with GPS integration example"""

from pathlib import Path
from argus_track import (
    TrackerConfig,
    LightPostTracker,
    YOLODetector
)
from argus_track.utils import load_gps_data


def main():
    """Process video with GPS data for geolocation"""
    
    # Setup paths
    video_path = 'input/street_recording.mp4'
    gps_path = 'input/gps_data.csv'
    output_path = 'output/tracked_with_gps.mp4'
    
    # Check if files exist
    if not Path(video_path).exists():
        print(f"Video file not found: {video_path}")
        return
    
    # Load configuration from YAML file
    try:
        config = TrackerConfig.from_yaml('config/tracker_config.yaml')
    except FileNotFoundError:
        print("Config file not found, using defaults")
        config = TrackerConfig(
            track_thresh=0.5,
            match_thresh=0.8,
            track_buffer=50,
            static_threshold=2.0,
            min_static_frames=5
        )
    
    # Initialize YOLO detector
    try:
        detector = YOLODetector(
            model_path='models/yolov4.weights',
            config_path='models/yolov4.cfg',
            target_classes=['light_post', 'street_light', 'pole']
        )
        print("Using YOLO detector")
    except Exception as e:
        print(f"Failed to load YOLO: {e}")
        print("Falling back to mock detector")
        from bytetrack_lightpost import MockDetector
        detector = MockDetector(target_classes=['light_post'])
    
    # Load GPS data
    gps_data = None
    if Path(gps_path).exists():
        gps_data = load_gps_data(gps_path)
        print(f"Loaded {len(gps_data)} GPS data points")
    else:
        print("No GPS data found, proceeding without geolocation")
    
    # Create tracker
    tracker = LightPostTracker(config, detector)
    
    # Process video
    print(f"Processing video: {video_path}")
    tracks = tracker.process_video(
        video_path=video_path,
        gps_data=gps_data,
        output_path=output_path,
        save_results=True
    )
    
    # Analyze results
    print(f"\nTracking Results:")
    print(f"Total tracks: {len(tracks)}")
    
    # Get statistics
    stats = tracker.get_track_statistics()
    for key, value in stats.items():
        print(f"{key}: {value}")
    
    # Analyze static objects
    static_analysis = tracker.analyze_static_objects()
    static_tracks = [tid for tid, is_static in static_analysis.items() if is_static]
    
    print(f"\nStatic Light Posts:")
    for track_id in static_tracks:
        track = tracker.tracker.tracks[track_id]
        print(f"Track {track_id}: {len(track.detections)} detections")
        
        # If GPS data available, show estimated position
        if gps_data and track_id in tracker.gps_tracks:
            positions = tracker.estimate_3d_positions(track_id)
            if positions:
                last_pos = positions[-1]
                print(f"  Location: ({last_pos['x']:.6f}, {last_pos['y']:.6f})")
    
    print(f"\nOutput saved to: {output_path}")
    print(f"Results saved to: {Path(video_path).with_suffix('.json')}")


if __name__ == "__main__":
    main()

================
File: images/bytetrack-workflow-diagram.svg
================
<svg viewBox="0 0 800 600" xmlns="http://www.w3.org/2000/svg">
  <!-- Title -->
  <text x="400" y="30" font-size="20" font-weight="bold" text-anchor="middle">ByteTrack Workflow for Light Post Tracking</text>
  
  <!-- Input Frame -->
  <rect x="20" y="60" width="120" height="80" fill="#e3f2fd" stroke="#1976d2" stroke-width="2"/>
  <text x="80" y="100" text-anchor="middle" font-size="14">Input Frame</text>
  <text x="80" y="120" text-anchor="middle" font-size="12">(with detections)</text>
  
  <!-- Detection Preprocessing -->
  <rect x="180" y="60" width="140" height="80" fill="#f3e5f5" stroke="#7b1fa2" stroke-width="2"/>
  <text x="250" y="90" text-anchor="middle" font-size="14">Split Detections</text>
  <text x="250" y="110" text-anchor="middle" font-size="12">High Score (>0.5)</text>
  <text x="250" y="130" text-anchor="middle" font-size="12">Low Score (0.5)</text>
  
  <!-- First Association -->
  <rect x="360" y="40" width="140" height="60" fill="#e8f5e9" stroke="#388e3c" stroke-width="2"/>
  <text x="430" y="70" text-anchor="middle" font-size="14">First Association</text>
  <text x="430" y="90" text-anchor="middle" font-size="12">(High Score + Tracks)</text>
  
  <!-- Second Association -->
  <rect x="360" y="120" width="140" height="60" fill="#fff3e0" stroke="#f57c00" stroke-width="2"/>
  <text x="430" y="150" text-anchor="middle" font-size="14">Second Association</text>
  <text x="430" y="170" text-anchor="middle" font-size="12">(Low Score + Unmatched)</text>
  
  <!-- Track Management -->
  <rect x="540" y="60" width="140" height="80" fill="#fce4ec" stroke="#c2185b" stroke-width="2"/>
  <text x="610" y="90" text-anchor="middle" font-size="14">Track Management</text>
  <text x="610" y="110" text-anchor="middle" font-size="12"> Update matched</text>
  <text x="610" y="130" text-anchor="middle" font-size="12"> Create new tracks</text>
  
  <!-- Arrows -->
  <defs>
    <marker id="arrowhead" markerWidth="10" markerHeight="7" 
     refX="0" refY="3.5" orient="auto">
      <polygon points="0 0, 10 3.5, 0 7" fill="#333" />
    </marker>
  </defs>
  
  <line x1="140" y1="100" x2="180" y2="100" stroke="#333" stroke-width="2" marker-end="url(#arrowhead)"/>
  <line x1="320" y1="100" x2="360" y2="80" stroke="#333" stroke-width="2" marker-end="url(#arrowhead)"/>
  <line x1="320" y1="100" x2="360" y2="140" stroke="#333" stroke-width="2" marker-end="url(#arrowhead)"/>
  <line x1="500" y1="70" x2="540" y2="90" stroke="#333" stroke-width="2" marker-end="url(#arrowhead)"/>
  <line x1="500" y1="150" x2="540" y2="110" stroke="#333" stroke-width="2" marker-end="url(#arrowhead)"/>
  
  <!-- Kalman Filter Box -->
  <rect x="180" y="200" width="440" height="100" fill="#f5f5f5" stroke="#666" stroke-width="2" stroke-dasharray="5,5"/>
  <text x="400" y="230" text-anchor="middle" font-size="16" font-weight="bold">Kalman Filter (per track)</text>
  
  <!-- Kalman States -->
  <rect x="200" y="250" width="100" height="40" fill="#e1f5fe" stroke="#0288d1" stroke-width="1"/>
  <text x="250" y="270" text-anchor="middle" font-size="12">State</text>
  <text x="250" y="285" text-anchor="middle" font-size="10">[x,y,w,h,vx,vy,vw,vh]</text>
  
  <rect x="320" y="250" width="100" height="40" fill="#f3e5f5" stroke="#7b1fa2" stroke-width="1"/>
  <text x="370" y="270" text-anchor="middle" font-size="12">Predict</text>
  <text x="370" y="285" text-anchor="middle" font-size="10">Next position</text>
  
  <rect x="440" y="250" width="100" height="40" fill="#e8f5e9" stroke="#388e3c" stroke-width="1"/>
  <text x="490" y="270" text-anchor="middle" font-size="12">Update</text>
  <text x="490" y="285" text-anchor="middle" font-size="10">With detection</text>
  
  <!-- Track States -->
  <text x="400" y="340" text-anchor="middle" font-size="16" font-weight="bold">Track States</text>
  
  <rect x="100" y="360" width="120" height="50" fill="#e8f5e9" stroke="#388e3c" stroke-width="2"/>
  <text x="160" y="385" text-anchor="middle" font-size="14">Tentative</text>
  <text x="160" y="400" text-anchor="middle" font-size="12">(< 3 frames)</text>
  
  <rect x="260" y="360" width="120" height="50" fill="#fff9c4" stroke="#f9a825" stroke-width="2"/>
  <text x="320" y="385" text-anchor="middle" font-size="14">Confirmed</text>
  <text x="320" y="400" text-anchor="middle" font-size="12">( 3 frames)</text>
  
  <rect x="420" y="360" width="120" height="50" fill="#ffebee" stroke="#c62828" stroke-width="2"/>
  <text x="480" y="385" text-anchor="middle" font-size="14">Lost</text>
  <text x="480" y="400" text-anchor="middle" font-size="12">(no match)</text>
  
  <rect x="580" y="360" width="120" height="50" fill="#e0e0e0" stroke="#616161" stroke-width="2"/>
  <text x="640" y="385" text-anchor="middle" font-size="14">Removed</text>
  <text x="640" y="400" text-anchor="middle" font-size="12">(> 30 frames lost)</text>
  
  <!-- State Transitions -->
  <line x1="220" y1="385" x2="260" y2="385" stroke="#333" stroke-width="2" marker-end="url(#arrowhead)"/>
  <line x1="380" y1="385" x2="420" y2="385" stroke="#333" stroke-width="2" marker-end="url(#arrowhead)"/>
  <line x1="540" y1="385" x2="580" y2="385" stroke="#333" stroke-width="2" marker-end="url(#arrowhead)"/>
  
  <!-- Light Post Specific Features -->
  <rect x="50" y="450" width="700" height="120" fill="#f8f9fa" stroke="#333" stroke-width="2"/>
  <text x="400" y="480" text-anchor="middle" font-size="16" font-weight="bold">Light Post Tracking Optimizations</text>
  
  <rect x="70" y="500" width="150" height="50" fill="#e3f2fd" stroke="#1565c0" stroke-width="1"/>
  <text x="145" y="520" text-anchor="middle" font-size="12" font-weight="bold">Static Assumption</text>
  <text x="145" y="535" text-anchor="middle" font-size="11">Low velocity noise</text>
  <text x="145" y="548" text-anchor="middle" font-size="11">in Kalman filter</text>
  
  <rect x="250" y="500" width="150" height="50" fill="#f3e5f5" stroke="#6a1b9a" stroke-width="1"/>
  <text x="325" y="520" text-anchor="middle" font-size="12" font-weight="bold">GPS Integration</text>
  <text x="325" y="535" text-anchor="middle" font-size="11">Track 3D positions</text>
  <text x="325" y="548" text-anchor="middle" font-size="11">for triangulation</text>
  
  <rect x="430" y="500" width="150" height="50" fill="#e8f5e9" stroke="#2e7d32" stroke-width="1"/>
  <text x="505" y="520" text-anchor="middle" font-size="12" font-weight="bold">Appearance Buffer</text>
  <text x="505" y="535" text-anchor="middle" font-size="11">Store visual features</text>
  <text x="505" y="548" text-anchor="middle" font-size="11">for re-identification</text>
  
  <rect x="610" y="500" width="120" height="50" fill="#fff3e0" stroke="#e65100" stroke-width="1"/>
  <text x="670" y="520" text-anchor="middle" font-size="12" font-weight="bold">ID Persistence</text>
  <text x="670" y="535" text-anchor="middle" font-size="11">Long buffer for</text>
  <text x="670" y="548" text-anchor="middle" font-size="11">occluded objects</text>
</svg>

================
File: tests/aditional_comprehensive.py
================
"""Additional comprehensive tests"""

import pytest
import numpy as np
from unittest.mock import Mock, patch

from argus_track import (
    TrackerConfig,
    LightPostTracker,
    ByteTrack,
    MockDetector
)
from argus_track.core import Detection, Track, GPSData
from argus_track.utils import calculate_iou, calculate_iou_matrix


class TestByteTrackIntegration:
    """Integration tests for ByteTrack"""
    
    def test_track_lifecycle(self):
        """Test complete track lifecycle"""
        config = TrackerConfig(
            track_thresh=0.5,
            match_thresh=0.8,
            track_buffer=30
        )
        tracker = ByteTrack(config)
        
        # Frame 1: New detection
        detections = [
            Detection(
                bbox=np.array([100, 100, 200, 200]),
                score=0.9,
                class_id=0,
                frame_id=0
            )
        ]
        tracks = tracker.update(detections)
        
        assert len(tracks) == 1
        assert tracks[0].state == 'tentative'
        assert tracks[0].track_id == 0
        
        # Frame 2-4: Confirm track
        for frame_id in range(1, 4):
            detections = [
                Detection(
                    bbox=np.array([102, 102, 202, 202]),
                    score=0.9,
                    class_id=0,
                    frame_id=frame_id
                )
            ]
            tracks = tracker.update(detections)
        
        assert len(tracks) == 1
        assert tracks[0].state == 'confirmed'
        assert tracks[0].hits == 4
        
        # Frame 5-35: No detections (test lost state)
        for frame_id in range(4, 35):
            tracks = tracker.update([])
        
        # Track should be removed after buffer
        assert len(tracker.active_tracks) == 0
        assert len(tracker.removed_tracks) == 1
    
    def test_two_stage_association(self):
        """Test two-stage association strategy"""
        config = TrackerConfig(
            track_thresh=0.5,
            match_thresh=0.8
        )
        tracker = ByteTrack(config)
        
        # Create initial track
        initial_det = Detection(
            bbox=np.array([100, 100, 200, 200]),
            score=0.9,
            class_id=0,
            frame_id=0
        )
        tracker.update([initial_det])
        
        # Test high and low confidence detections
        high_conf = Detection(
            bbox=np.array([105, 105, 205, 205]),
            score=0.8,
            class_id=0,
            frame_id=1
        )
        low_conf = Detection(
            bbox=np.array([110, 110, 210, 210]),
            score=0.3,
            class_id=0,
            frame_id=1
        )
        
        # Both detections should associate with the track
        tracks = tracker.update([high_conf, low_conf])
        
        # Only high confidence should match in first stage
        assert len(tracks) == 1
        assert tracks[0].hits == 2
    
    def test_track_overlap_handling(self):
        """Test handling of overlapping tracks"""
        config = TrackerConfig()
        tracker = ByteTrack(config)
        
        # Create two overlapping detections
        det1 = Detection(
            bbox=np.array([100, 100, 200, 200]),
            score=0.9,
            class_id=0,
            frame_id=0
        )
        det2 = Detection(
            bbox=np.array([150, 150, 250, 250]),
            score=0.9,
            class_id=0,
            frame_id=0
        )
        
        tracks = tracker.update([det1, det2])
        assert len(tracks) == 2
        
        # Update with single detection in overlap area
        overlap_det = Detection(
            bbox=np.array([140, 140, 210, 210]),
            score=0.9,
            class_id=0,
            frame_id=1
        )
        
        tracks = tracker.update([overlap_det])
        # Should maintain both tracks (one matched, one lost)
        assert len(tracker.active_tracks) == 1
        assert len(tracker.lost_tracks) == 1


class TestStaticObjectAnalysis:
    """Test static object detection"""
    
    def test_static_detection(self):
        """Test detection of static objects"""
        config = TrackerConfig(
            static_threshold=2.0,
            min_static_frames=5
        )
        
        detector = MockDetector()
        tracker = LightPostTracker(config, detector)
        
        # Create track with minimal movement
        track = Track(track_id=0)
        base_pos = np.array([100, 100])
        
        for i in range(10):
            # Add small noise to simulate real detection
            noise = np.random.normal(0, 0.5, 2)
            bbox = np.array([
                base_pos[0] + noise[0],
                base_pos[1] + noise[1],
                base_pos[0] + noise[0] + 50,
                base_pos[1] + noise[1] + 100
            ])
            
            detection = Detection(
                bbox=bbox,
                score=0.9,
                class_id=0,
                frame_id=i
            )
            track.detections.append(detection)
        
        # Add to tracker
        tracker.tracker.tracks[0] = track
        
        # Analyze static objects
        static_analysis = tracker.analyze_static_objects()
        
        assert 0 in static_analysis
        assert static_analysis[0] == True


class TestGPSIntegration:
    """Test GPS functionality"""
    
    def test_gps_interpolation(self):
        """Test GPS data interpolation"""
        gps_data = [
            GPSData(
                timestamp=0.0,
                latitude=40.0,
                longitude=-74.0,
                altitude=10.0,
                heading=90.0
            ),
            GPSData(
                timestamp=1.0,
                latitude=40.001,
                longitude=-74.001,
                altitude=11.0,
                heading=92.0
            )
        ]
        
        from argus_track.utils.gps_utils import GPSInterpolator
        interpolator = GPSInterpolator(gps_data)
        
        # Test interpolation at 0.5 seconds
        interpolated = interpolator.interpolate(0.5)
        
        assert abs(interpolated.latitude - 40.0005) < 1e-6
        assert abs(interpolated.longitude - (-74.0005)) < 1e-6
        assert abs(interpolated.altitude - 10.5) < 0.01
        assert abs(interpolated.heading - 91.0) < 0.01
    
    def test_coordinate_transformation(self):
        """Test GPS coordinate transformations"""
        from argus_track.utils.gps_utils import CoordinateTransformer
        
        transformer = CoordinateTransformer(
            reference_lat=40.0,
            reference_lon=-74.0
        )
        
        # Test conversion to local coordinates
        local_x, local_y = transformer.gps_to_local(40.001, -74.001)
        
        # Should be approximately 111m north and 85m west
        assert abs(local_x - (-85)) < 10  # meters
        assert abs(local_y - 111) < 10  # meters
        
        # Test round-trip conversion
        lat2, lon2 = transformer.local_to_gps(local_x, local_y)
        assert abs(lat2 - 40.001) < 1e-6
        assert abs(lon2 - (-74.001)) < 1e-6


class TestPerformance:
    """Test performance monitoring"""
    
    def test_performance_monitor(self):
        """Test performance monitoring functionality"""
        from argus_track.utils.performance import PerformanceMonitor
        
        monitor = PerformanceMonitor(
            monitor_memory=True,
            monitor_gpu=False,
            log_interval=10
        )
        
        # Simulate processing
        with monitor.timer('frame'):
            time.sleep(0.01)  # Simulate 10ms processing
        
        with monitor.timer('detection'):
            time.sleep(0.005)  # Simulate 5ms detection
        
        with monitor.timer('tracking'):
            time.sleep(0.003)  # Simulate 3ms tracking
        
        monitor.update()
        
        # Check metrics
        assert len(monitor.metrics.frame_times) == 1
        assert monitor.metrics.frame_times[0] >= 0.01
        assert len(monitor.metrics.detection_times) == 1
        assert monitor.metrics.detection_times[0] >= 0.005
        
        # Generate report
        report = monitor.generate_report()
        assert 'summary' in report
        assert 'statistics' in report
        assert report['summary']['total_frames'] == 1


class TestConfigValidation:
    """Test configuration validation"""
    
    def test_valid_config(self):
        """Test validation of valid configuration"""
        from argus_track.utils.config_validator import ConfigValidator
        
        config = TrackerConfig()
        errors = ConfigValidator.validate_tracker_config(config)
        assert len(errors) == 0
    
    def test_invalid_config(self):
        """Test validation of invalid configuration"""
        from argus_track.utils.config_validator import ConfigValidator
        
        config = TrackerConfig(
            track_thresh=1.5,  # Invalid: > 1
            match_thresh=-0.1,  # Invalid: < 0
            track_buffer=0,  # Invalid: < 1
            min_box_area=-10  # Invalid: < 0
        )
        
        errors = ConfigValidator.validate_tracker_config(config)
        assert len(errors) >= 4
        assert any('track_thresh' in error for error in errors)
        assert any('match_thresh' in error for error in errors)

================
File: tests/conftest.py
================
"""
Pytest configuration file
"""

import pytest
import sys
from pathlib import Path

# Add project root to Python path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))


@pytest.fixture
def sample_detection():
    """Provide sample detection for testing"""
    import numpy as np
    from argus_track.core import Detection
    
    return Detection(
        bbox=np.array([100, 200, 150, 300]),
        score=0.95,
        class_id=0,
        frame_id=1
    )


@pytest.fixture
def sample_track():
    """Provide sample track for testing"""
    from argus_track.core import Track
    
    return Track(
        track_id=1,
        state='confirmed',
        hits=5,
        age=10
    )


@pytest.fixture
def sample_config():
    """Provide sample configuration for testing"""
    from argus_track import TrackerConfig
    
    return TrackerConfig(
        track_thresh=0.5,
        match_thresh=0.8,
        track_buffer=50
    )


@pytest.fixture
def mock_video_capture(monkeypatch):
    """Mock cv2.VideoCapture for testing"""
    import cv2
    import numpy as np
    
    class MockVideoCapture:
        def __init__(self, path):
            self.path = path
            self.frame_count = 100
            self.current_frame = 0
            
        def read(self):
            if self.current_frame < self.frame_count:
                self.current_frame += 1
                return True, np.zeros((720, 1280, 3), dtype=np.uint8)
            return False, None
            
        def get(self, prop):
            if prop == cv2.CAP_PROP_FPS:
                return 30.0
            elif prop == cv2.CAP_PROP_FRAME_COUNT:
                return self.frame_count
            elif prop == cv2.CAP_PROP_FRAME_WIDTH:
                return 1280
            elif prop == cv2.CAP_PROP_FRAME_HEIGHT:
                return 720
            return 0
            
        def release(self):
            pass
    
    monkeypatch.setattr('cv2.VideoCapture', MockVideoCapture)
    return MockVideoCapture

================
File: tests/test_core.py
================
"""Test module for core data structures"""

import pytest
import numpy as np

from argus_track.core import Detection, Track, GPSData


class TestDetection:
    """Test Detection class"""
    
    def test_detection_creation(self):
        """Test creating a detection"""
        det = Detection(
            bbox=np.array([100, 200, 150, 300]),
            score=0.95,
            class_id=0,
            frame_id=1
        )
        
        assert det.score == 0.95
        assert det.class_id == 0
        assert det.frame_id == 1
        np.testing.assert_array_equal(det.bbox, [100, 200, 150, 300])
    
    def test_detection_properties(self):
        """Test detection property calculations"""
        det = Detection(
            bbox=np.array([100, 200, 200, 400]),
            score=0.9,
            class_id=0,
            frame_id=1
        )
        
        # Test tlbr property
        np.testing.assert_array_equal(det.tlbr, [100, 200, 200, 400])
        
        # Test xywh property
        xywh = det.xywh
        assert xywh[0] == 150  # center x
        assert xywh[1] == 300  # center y
        assert xywh[2] == 100  # width
        assert xywh[3] == 200  # height
        
        # Test area
        assert det.area == 20000
        
        # Test center
        center = det.center
        assert center[0] == 150
        assert center[1] == 300
    
    def test_detection_serialization(self):
        """Test detection to/from dict"""
        det = Detection(
            bbox=np.array([10, 20, 30, 40]),
            score=0.85,
            class_id=1,
            frame_id=5
        )
        
        # To dict
        det_dict = det.to_dict()
        assert det_dict['bbox'] == [10, 20, 30, 40]
        assert det_dict['score'] == 0.85
        assert det_dict['class_id'] == 1
        assert det_dict['frame_id'] == 5
        
        # From dict
        det2 = Detection.from_dict(det_dict)
        assert det2.score == det.score
        assert det2.class_id == det.class_id
        np.testing.assert_array_equal(det2.bbox, det.bbox)


class TestTrack:
    """Test Track class"""
    
    def test_track_creation(self):
        """Test creating a track"""
        track = Track(track_id=1)
        
        assert track.track_id == 1
        assert track.state == 'tentative'
        assert track.hits == 0
        assert track.age == 0
        assert len(track.detections) == 0
    
    def test_track_properties(self):
        """Test track properties"""
        track = Track(track_id=1, state='confirmed')
        
        # Test is_confirmed
        assert track.is_confirmed is True
        
        # Test is_active
        assert track.is_active is True
        
        track.state = 'lost'
        assert track.is_confirmed is False
        assert track.is_active is False
    
    def test_track_with_detections(self):
        """Test track with detections"""
        det1 = Detection(
            bbox=np.array([10, 20, 30, 40]),
            score=0.9,
            class_id=0,
            frame_id=1
        )
        det2 = Detection(
            bbox=np.array([12, 22, 32, 42]),
            score=0.85,
            class_id=0,
            frame_id=2
        )
        
        track = Track(track_id=1, detections=[det1, det2])
        
        assert len(track.detections) == 2
        assert track.last_detection == det2
        
        # Test trajectory
        trajectory = track.trajectory
        assert len(trajectory) == 2
        np.testing.assert_array_equal(trajectory[0], [20, 30])
        np.testing.assert_array_equal(trajectory[1], [22, 32])
    
    def test_track_to_tlbr(self):
        """Test getting track bounding box"""
        det = Detection(
            bbox=np.array([100, 200, 150, 300]),
            score=0.9,
            class_id=0,
            frame_id=1
        )
        
        track = Track(track_id=1, detections=[det])
        bbox = track.to_tlbr()
        np.testing.assert_array_equal(bbox, [100, 200, 150, 300])


class TestGPSData:
    """Test GPSData class"""
    
    def test_gps_creation(self):
        """Test creating GPS data"""
        gps = GPSData(
            timestamp=1234567890.0,
            latitude=40.7128,
            longitude=-74.0060,
            altitude=10.5,
            heading=45.0,
            accuracy=1.5
        )
        
        assert gps.timestamp == 1234567890.0
        assert gps.latitude == 40.7128
        assert gps.longitude == -74.0060
        assert gps.altitude == 10.5
        assert gps.heading == 45.0
        assert gps.accuracy == 1.5
    
    def test_gps_serialization(self):
        """Test GPS to/from dict"""
        gps = GPSData(
            timestamp=1234567890.0,
            latitude=40.7128,
            longitude=-74.0060,
            altitude=10.5,
            heading=45.0
        )
        
        # To dict
        gps_dict = gps.to_dict()
        assert gps_dict['timestamp'] == 1234567890.0
        assert gps_dict['latitude'] == 40.7128
        assert gps_dict['accuracy'] == 1.0  # default value
        
        # From dict
        gps2 = GPSData.from_dict(gps_dict)
        assert gps2.timestamp == gps.timestamp
        assert gps2.latitude == gps.latitude
        assert gps2.longitude == gps.longitude
    
    def test_gps_from_csv(self):
        """Test creating GPS from CSV line"""
        line = "1234567890.0,40.7128,-74.0060,10.5,45.0,2.0"
        gps = GPSData.from_csv_line(line)
        
        assert gps.timestamp == 1234567890.0
        assert gps.latitude == 40.7128
        assert gps.longitude == -74.0060
        assert gps.altitude == 10.5
        assert gps.heading == 45.0
        assert gps.accuracy == 2.0
        
        # Test without accuracy
        line2 = "1234567890.0,40.7128,-74.0060,10.5,45.0"
        gps2 = GPSData.from_csv_line(line2)
        assert gps2.accuracy == 1.0  # default
        
        # Test invalid line
        with pytest.raises(ValueError):
            GPSData.from_csv_line("invalid,data")

================
File: tests/test_detector.py
================
"""Test module for detectors"""

import pytest
import numpy as np
from unittest.mock import patch, MagicMock

from argus_track.detectors import (
    ObjectDetector,
    YOLODetector,
    MockDetector
)


class TestMockDetector:
    """Test MockDetector class"""
    
    def test_mock_detector_creation(self):
        """Test creating mock detector"""
        detector = MockDetector(target_classes=['light_post'])
        
        assert 'light_post' in detector.target_classes
        assert detector.frame_count == 0
    
    def test_mock_detector_detection(self):
        """Test mock detection generation"""
        detector = MockDetector(target_classes=['light_post'])
        
        # Create dummy frame
        frame = np.zeros((720, 1280, 3), dtype=np.uint8)
        
        # Get detections
        detections = detector.detect(frame)
        
        assert len(detections) > 0
        
        for det in detections:
            assert 'bbox' in det
            assert 'score' in det
            assert 'class_name' in det
            assert 'class_id' in det
            assert det['class_name'] in detector.target_classes
            assert 0.7 <= det['score'] <= 1.0
    
    def test_mock_detector_consistency(self):
        """Test that mock detector produces consistent results"""
        detector = MockDetector(target_classes=['light_post'])
        frame = np.zeros((720, 1280, 3), dtype=np.uint8)
        
        # Get detections from multiple frames
        detections1 = detector.detect(frame)
        detections2 = detector.detect(frame)
        
        # Should produce similar but slightly different results
        assert len(detections1) == len(detections2)
        
        # Check that positions are slightly different (due to noise)
        for det1, det2 in zip(detections1, detections2):
            bbox1 = np.array(det1['bbox'])
            bbox2 = np.array(det2['bbox'])
            diff = np.abs(bbox1 - bbox2)
            assert np.all(diff < 20)  # Small movement


class TestYOLODetector:
    """Test YOLODetector class"""
    
    @patch('cv2.dnn.readNet')
    def test_yolo_detector_creation(self, mock_readnet):
        """Test creating YOLO detector"""
        # Mock cv2.dnn.readNet
        mock_net = MagicMock()
        mock_readnet.return_value = mock_net
        mock_net.getLayerNames.return_value = ['layer1', 'layer2', 'layer3']
        mock_net.getUnconnectedOutLayers.return_value = np.array([2, 3])
        
        # Mock file operations
        with patch('builtins.open', create=True) as mock_open:
            mock_open.return_value.__enter__.return_value.readlines.return_value = [
                'light_post\n', 'street_light\n'
            ]
            
            detector = YOLODetector(
                model_path='yolo.weights',
                config_path='yolo.cfg',
                target_classes=['light_post']
            )
        
        assert 'light_post' in detector.target_classes
        assert len(detector.class_names) == 2
        mock_readnet.assert_called_once()
    
    @patch('cv2.dnn.readNet')
    def test_yolo_detector_detection(self, mock_readnet):
        """Test YOLO detection process"""
        # Mock network
        mock_net = MagicMock()
        mock_readnet.return_value = mock_net
        mock_net.getLayerNames.return_value = ['layer1', 'layer2', 'layer3']
        mock_net.getUnconnectedOutLayers.return_value = np.array([2, 3])
        
        # Mock detection output
        mock_output = np.zeros((1, 85))  # YOLO output format
        mock_output[0, 0] = 0.5  # center x
        mock_output[0, 1] = 0.5  # center y
        mock_output[0, 2] = 0.1  # width
        mock_output[0, 3] = 0.2  # height
        mock_output[0, 4] = 0.9  # objectness
        mock_output[0, 5] = 0.95  # class 0 score (light_post)
        
        mock_net.forward.return_value = [mock_output]
        
        # Mock NMS
        with patch('cv2.dnn.NMSBoxes') as mock_nms:
            mock_nms.return_value = np.array([0])
            
            # Create detector
            with patch('builtins.open', create=True) as mock_open:
                mock_open.return_value.__enter__.return_value.readlines.return_value = [
                    'light_post\n'
                ]
                
                detector = YOLODetector(
                    model_path='yolo.weights',
                    config_path='yolo.cfg'
                )
            
            # Test detection
            frame = np.zeros((480, 640, 3), dtype=np.uint8)
            detections = detector.detect(frame)
            
            assert len(detections) == 1
            assert detections[0]['class_name'] == 'light_post'
            assert detections[0]['score'] > 0.9
    
    def test_yolo_detector_backend(self):
        """Test setting YOLO backend"""
        with patch('cv2.dnn.readNet') as mock_readnet:
            mock_net = MagicMock()
            mock_readnet.return_value = mock_net
            mock_net.getLayerNames.return_value = ['layer']
            mock_net.getUnconnectedOutLayers.return_value = np.array([1])
            
            with patch('builtins.open', create=True) as mock_open:
                mock_open.return_value.__enter__.return_value.readlines.return_value = []
                
                detector = YOLODetector(
                    model_path='yolo.weights',
                    config_path='yolo.cfg'
                )
                
                # Test setting backend
                detector.set_backend('cuda')
                mock_net.setPreferableBackend.assert_called()
                mock_net.setPreferableTarget.assert_called()


class TestObjectDetectorInterface:
    """Test ObjectDetector abstract interface"""
    
    def test_detector_interface(self):
        """Test that concrete detectors implement required methods"""
        # MockDetector should implement all required methods
        detector = MockDetector()
        
        assert hasattr(detector, 'detect')
        assert hasattr(detector, 'get_class_names')
        assert callable(detector.detect)
        assert callable(detector.get_class_names)
        
        # Test that methods work
        frame = np.zeros((100, 100, 3), dtype=np.uint8)
        detections = detector.detect(frame)
        class_names = detector.get_class_names()
        
        assert isinstance(detections, list)
        assert isinstance(class_names, list)

================
File: tests/test_integration.py
================
# tests/test_integration.py

"""Integration tests for ByteTrack Light Post Tracking system"""

import pytest
import numpy as np
import tempfile
from pathlib import Path
import json
import os

from argus_track import (
    TrackerConfig,
    Detection,
    Track,
    GPSData,
    ByteTrack, 
    LightPostTracker, 
    MockDetector
)
from argus_track.utils.gps_utils import GeoLocation


class TestBasicTracking:
    """Test basic tracking functionality"""
    
    def test_track_lifecycle(self):
        """Test full track lifecycle from creation to removal"""
        config = TrackerConfig(
            track_thresh=0.5,
            match_thresh=0.8,
            track_buffer=10  # Short buffer for testing
        )
        tracker = ByteTrack(config)
        
        # Frame 1: Create track
        detections = [
            Detection(
                bbox=np.array([100, 100, 200, 200]),
                score=0.9,
                class_id=0,
                frame_id=0
            )
        ]
        tracks = tracker.update(detections)
        assert len(tracks) == 1
        assert tracks[0].state == 'tentative'
        track_id = tracks[0].track_id
        
        # Frames 2-3: Confirm track
        for i in range(1, 3):
            detections = [
                Detection(
                    bbox=np.array([102, 102, 202, 202]),
                    score=0.9,
                    class_id=0,
                    frame_id=i
                )
            ]
            tracks = tracker.update(detections)
        
        assert len(tracks) == 1
        assert tracks[0].state == 'confirmed'
        assert tracks[0].track_id == track_id
        
        # Frames 4-14: No detections, track should be lost then removed
        for i in range(3, 15):
            tracks = tracker.update([])
        
        # Track should be removed after buffer expires
        assert len(tracker.active_tracks) == 0
        assert len(tracker.lost_tracks) == 0
        assert len(tracker.removed_tracks) == 1
        assert tracker.removed_tracks[0].track_id == track_id
    
    def test_two_stage_association(self):
        """Test two-stage association strategy"""
        config = TrackerConfig(
            track_thresh=0.5,
            match_thresh=0.8
        )
        tracker = ByteTrack(config)
        
        # Create initial track
        init_det = Detection(
            bbox=np.array([100, 100, 200, 200]),
            score=0.9,
            class_id=0,
            frame_id=0
        )
        tracker.update([init_det])
        
        # Next frame: provide high and low confidence detections
        high_conf = Detection(
            bbox=np.array([102, 102, 202, 202]),  # Close to previous
            score=0.9,
            class_id=0,
            frame_id=1
        )
        
        low_conf = Detection(
            bbox=np.array([300, 300, 400, 400]),  # Far from previous
            score=0.3,
            class_id=0,
            frame_id=1
        )
        
        # Update with both detections
        tracks = tracker.update([high_conf, low_conf])
        
        # Should have 2 tracks: one matched with high conf, one new from low conf
        assert len(tracks) == 2
        assert any(t.hits == 2 for t in tracks)  # One track matched twice
        assert any(t.hits == 1 for t in tracks)  # One new track


class TestLightPostTrackerWithGPS:
    """Test LightPostTracker with GPS integration"""
    
    def test_gps_integration(self):
        """Test GPS data integration with tracks"""
        config = TrackerConfig()
        detector = MockDetector(target_classes=['light_post'])
        tracker = LightPostTracker(config, detector)
        
        # Create sample frame
        frame = np.zeros((480, 640, 3), dtype=np.uint8)
        
        # Create sample GPS data
        gps_data = GPSData(
            timestamp=1000.0,
            latitude=40.7128,
            longitude=-74.0060,
            altitude=10.0,
            heading=0.0
        )
        
        # Process frame with GPS
        tracks = tracker.process_frame(frame, 0, gps_data)
        
        # Detector should have created some tracks
        assert len(tracks) > 0
        
        # GPS data should be associated with tracks
        for track in tracks:
            assert track.track_id in tracker.gps_tracks
            assert len(tracker.gps_tracks[track.track_id]) == 1
            assert tracker.gps_tracks[track.track_id][0].latitude == 40.7128
    
    def test_location_estimation(self):
        """Test location estimation from GPS data"""
        config = TrackerConfig()
        detector = MockDetector(target_classes=['light_post'])
        tracker = LightPostTracker(config, detector)
        
        # Create sample frame
        frame = np.zeros((480, 640, 3), dtype=np.uint8)
        
        # Create GPS data sequence with slight movement
        gps_sequence = [
            GPSData(timestamp=1000.0, latitude=40.7128, longitude=-74.0060, altitude=10.0, heading=0.0),
            GPSData(timestamp=1033.0, latitude=40.7129, longitude=-74.0061, altitude=10.0, heading=0.0),
            GPSData(timestamp=1066.0, latitude=40.7127, longitude=-74.0059, altitude=10.0, heading=0.0),
        ]
        
        # Process multiple frames with GPS
        for i, gps in enumerate(gps_sequence):
            tracker.process_frame(frame, i, gps)
        
        # Make some tracks static
        for track in tracker.tracker.active_tracks:
            # Mock static detection logic
            track.age = 10  # Enough frames to be considered static
            track.detections = [track.detections[0]] * max(3, len(track.detections))
        
        # Estimate locations
        locations = tracker.estimate_track_locations()
        
        # Check if locations were computed
        assert len(locations) > 0
        
        # Check location properties
        for track_id, location in locations.items():
            assert isinstance(location, GeoLocation)
            assert 40.7 < location.latitude < 40.8
            assert -74.1 < location.longitude < -74.0
            assert 0.0 <= location.reliability <= 1.0
    
    @pytest.mark.skipif(not os.path.exists('/tmp'), reason="Requires /tmp directory")
    def test_geojson_export(self):
        """Test exporting locations to GeoJSON"""
        config = TrackerConfig()
        detector = MockDetector(target_classes=['light_post'])
        tracker = LightPostTracker(config, detector)
        
        # Create some fake track locations
        tracker.track_locations = {
            1: GeoLocation(latitude=40.7128, longitude=-74.0060, reliability=0.9, accuracy=1.0),
            2: GeoLocation(latitude=40.7130, longitude=-74.0065, reliability=0.8, accuracy=2.0),
            3: GeoLocation(latitude=40.7135, longitude=-74.0070, reliability=0.6, accuracy=5.0)
        }
        
        # Export to GeoJSON
        with tempfile.NamedTemporaryFile(suffix='.geojson', delete=False) as tmp:
            output_path = tmp.name
        
        try:
            tracker.export_locations_to_geojson(output_path)
            
            # Verify file exists
            assert Path(output_path).exists()
            
            # Check content
            with open(output_path, 'r') as f:
                geojson = json.load(f)
            
            assert geojson['type'] == 'FeatureCollection'
            assert len(geojson['features']) == 3
            
            # Check coordinates
            for feature in geojson['features']:
                assert feature['type'] == 'Feature'
                assert feature['geometry']['type'] == 'Point'
                assert len(feature['geometry']['coordinates']) == 2
                assert 'track_id' in feature['properties']
                assert 'reliability' in feature['properties']
        
        finally:
            # Clean up
            if Path(output_path).exists():
                Path(output_path).unlink()


class TestVectorizedOperations:
    """Test vectorized operations for performance"""
    
    def test_batch_kalman_predict(self):
        """Test batch Kalman prediction"""
        from argus_track.filters import batch_predict_kalman
        
        # Create multiple detections
        detections = [
            Detection(bbox=np.array([100, 100, 200, 200]), score=0.9, class_id=0, frame_id=0),
            Detection(bbox=np.array([300, 300, 400, 400]), score=0.9, class_id=0, frame_id=0),
            Detection(bbox=np.array([500, 500, 600, 600]), score=0.9, class_id=0, frame_id=0)
        ]
        
        # Create Kalman trackers
        from argus_track.filters import KalmanBoxTracker
        trackers = [KalmanBoxTracker(det) for det in detections]
        
        # Test batch prediction
        predictions = batch_predict_kalman(trackers)
        
        # Should return array of predictions
        assert isinstance(predictions, np.ndarray)
        assert predictions.shape == (3, 4)  # 3 trackers, 4 coordinates each
        
        # Check if predictions updated the trackers
        for tracker in trackers:
            assert tracker.age == 2
            assert tracker.time_since_update == 1
    
    def test_numba_iou_calculation(self):
        """Test numba-accelerated IoU calculation"""
        from argus_track.utils.iou import calculate_iou, calculate_iou_matrix_jit
        
        # Create bounding boxes
        bbox1 = np.array([100, 100, 200, 200])
        bbox2 = np.array([150, 150, 250, 250])
        
        # Calculate IoU
        iou = calculate_iou(bbox1, bbox2)
        assert 0.1 < iou < 0.2  # Roughly 1/9 overlap
        
        # Test with batches
        bboxes1 = np.array([
            [100, 100, 200, 200],
            [300, 300, 400, 400]
        ])
        
        bboxes2 = np.array([
            [150, 150, 250, 250],
            [350, 350, 450, 450]
        ])
        
        iou_matrix = calculate_iou_matrix_jit(bboxes1, bboxes2)
        assert iou_matrix.shape == (2, 2)
        assert 0.1 < iou_matrix[0, 0] < 0.2
        assert 0.1 < iou_matrix[1, 1] < 0.2
        assert iou_matrix[0, 1] == 0
        assert iou_matrix[1, 0] == 0


class TestErrorHandling:
    """Test error handling in the tracking system"""
    
    def test_invalid_video_path(self):
        """Test handling of invalid video path"""
        config = TrackerConfig()
        detector = MockDetector()
        tracker = LightPostTracker(config, detector)
        
        with pytest.raises(IOError):
            tracker.process_video("nonexistent_video.mp4")
    
    def test_gps_data_gaps(self):
        """Test handling of gaps in GPS data"""
        config = TrackerConfig()
        detector = MockDetector()
        tracker = LightPostTracker(config, detector)
        
        # Create frame
        frame = np.zeros((480, 640, 3), dtype=np.uint8)
        
        # Process frames with alternating GPS (simulating gaps)
        for i in range(10):
            if i % 2 == 0:
                # Even frames have GPS
                gps = GPSData(
                    timestamp=1000.0 + i * 33.3,
                    latitude=40.7128 + i * 0.0001,
                    longitude=-74.0060 - i * 0.0001,
                    altitude=10.0,
                    heading=0.0
                )
                tracker.process_frame(frame, i, gps)
            else:
                # Odd frames don't have GPS
                tracker.process_frame(frame, i, None)
        
        # Should still have GPS data for tracks
        assert len(tracker.gps_tracks) > 0
        
        # Can still estimate locations
        locations = tracker.estimate_track_locations()
        assert len(locations) > 0

================
File: .gitignore
================
# Byte-compiled / optimized / DLL files
__pycache__/
*.py[cod]
*$py.class

# C extensions
*.so

# Distribution / packaging
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
share/python-wheels/
*.egg-info/
.installed.cfg
*.egg
MANIFEST

# PyInstaller
#  Usually these files are written by a python script from a template
#  before PyInstaller builds the exe, so as to inject date/other infos into it.
*.manifest
*.spec

# Installer logs
pip-log.txt
pip-delete-this-directory.txt

# Unit test / coverage reports
htmlcov/
.tox/
.nox/
.coverage
.coverage.*
.cache
nosetests.xml
coverage.xml
*.cover
*.py,cover
.hypothesis/
.pytest_cache/
cover/

# Translations
*.mo
*.pot

# Django stuff:
*.log
local_settings.py
db.sqlite3
db.sqlite3-journal

# Flask stuff:
instance/
.webassets-cache

# Scrapy stuff:
.scrapy

# Sphinx documentation
docs/_build/

# PyBuilder
.pybuilder/
target/

# Jupyter Notebook
.ipynb_checkpoints

# IPython
profile_default/
ipython_config.py

# pyenv
#   For a library or package, you might want to ignore these files since the code is
#   intended to run in multiple environments; otherwise, check them in:
# .python-version

# pipenv
#   According to pypa/pipenv#598, it is recommended to include Pipfile.lock in version control.
#   However, in case of collaboration, if having platform-specific dependencies or dependencies
#   having no cross-platform support, pipenv may install dependencies that don't work, or not
#   install all needed dependencies.
#Pipfile.lock

# UV
#   Similar to Pipfile.lock, it is generally recommended to include uv.lock in version control.
#   This is especially recommended for binary packages to ensure reproducibility, and is more
#   commonly ignored for libraries.
#uv.lock

# poetry
#   Similar to Pipfile.lock, it is generally recommended to include poetry.lock in version control.
#   This is especially recommended for binary packages to ensure reproducibility, and is more
#   commonly ignored for libraries.
#   https://python-poetry.org/docs/basic-usage/#commit-your-poetrylock-file-to-version-control
#poetry.lock

# pdm
#   Similar to Pipfile.lock, it is generally recommended to include pdm.lock in version control.
#pdm.lock
#   pdm stores project-wide configurations in .pdm.toml, but it is recommended to not include it
#   in version control.
#   https://pdm.fming.dev/latest/usage/project/#working-with-version-control
.pdm.toml
.pdm-python
.pdm-build/

# PEP 582; used by e.g. github.com/David-OConnor/pyflow and github.com/pdm-project/pdm
__pypackages__/

# Celery stuff
celerybeat-schedule
celerybeat.pid

# SageMath parsed files
*.sage.py

# Environments
.env
.venv
env/
venv/
ENV/
env.bak/
venv.bak/

# Spyder project settings
.spyderproject
.spyproject

# Rope project settings
.ropeproject

# mkdocs documentation
/site

# mypy
.mypy_cache/
.dmypy.json
dmypy.json

# Pyre type checker
.pyre/

# pytype static type analyzer
.pytype/

# Cython debug symbols
cython_debug/

# PyCharm
#  JetBrains specific template is maintained in a separate JetBrains.gitignore that can
#  be found at https://github.com/github/gitignore/blob/main/Global/JetBrains.gitignore
#  and can be added to the global gitignore or merged into this file.  For a more nuclear
#  option (not recommended) you can uncomment the following to ignore the entire idea folder.
#.idea/

# Ruff stuff:
.ruff_cache/

# PyPI configuration file
.pypirc

================
File: LICENSE
================
MIT License

Copyright (c) 2025 Bell South

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.

================
File: README.md
================
# Argus Track: ByteTrack.

A specialized implementation of ByteTrack optimized for tracking light posts and similar static infrastructure in video sequences. Features GPS integration for geolocation mapping and 3D position estimation.

## Features

- **Optimized for Static Objects**: Specialized Kalman filter configuration for minimal movement
- **Two-Stage Association**: Robust tracking using high and low confidence detection matching
- **GPS Integration**: Synchronize tracks with GPS data for real-world positioning
- **Modular Architecture**: Clean separation of detection, tracking, and visualization components
- **Multiple Detector Support**: Works with YOLO and other object detection frameworks
- **Comprehensive Logging**: Detailed performance monitoring and debugging capabilities

## Installation

### From Source
```bash
git clone https://github.com/Bell-South/ArgusTrack.git
cd ArgusTrack
pip install -e .
```

### Using pip
```bash
pip install ArgusTrack
```

## Quick Start

### Basic Usage

```python
from argus_track import TrackerConfig, LightPostTracker, MockDetector

# Configure tracker
config = TrackerConfig(
    track_thresh=0.5,
    match_thresh=0.8,
    track_buffer=50
)

# Initialize detector and tracker
detector = MockDetector(target_classes=['light_post'])
tracker = LightPostTracker(config, detector)

# Process video
tracks = tracker.process_video(
    video_path='street_video.mp4',
    output_path='tracked_output.mp4'
)
```

### Command Line Interface

```bash
# Basic tracking
python -m argus_track input_video.mp4

# With GPS data and YOLO detector
python -m argus_track input_video.mp4 \
    --detector yolo \
    --gps gps_data.csv \
    --output tracked_output.mp4 \
    --config config.yaml
```

## Configuration

### Tracker Configuration

Create a `config.yaml` file:

```yaml
track_thresh: 0.5          # Minimum detection confidence
match_thresh: 0.8          # Minimum IoU for matching
track_buffer: 50           # Frames to keep lost tracks
min_box_area: 100.0        # Minimum detection area
static_threshold: 2.0      # Pixel movement threshold
min_static_frames: 5       # Frames to confirm static object
```

### GPS Data Format

GPS data should be in CSV format:

```csv
timestamp,latitude,longitude,altitude,heading,accuracy
1623456789.0,40.7128,-74.0060,10.5,45.0,1.0
1623456790.0,40.7129,-74.0061,10.6,45.2,1.0
```

## API Reference

### Core Classes

#### TrackerConfig
Configuration dataclass for the tracking system.

```python
@dataclass
class TrackerConfig:
    track_thresh: float = 0.5
    match_thresh: float = 0.8
    track_buffer: int = 50
    min_box_area: float = 100.0
    static_threshold: float = 2.0
    min_static_frames: int = 5
```

#### LightPostTracker
Main tracker class with GPS integration.

```python
tracker = LightPostTracker(config, detector, camera_config)
tracks = tracker.process_video(video_path, gps_data)
```

#### ByteTrack
Core ByteTrack algorithm implementation.

```python
tracker = ByteTrack(config)
active_tracks = tracker.update(detections)
```

### Detectors

#### YOLODetector
YOLO-based object detection.

```python
detector = YOLODetector(
    model_path='yolov4.weights',
    config_path='yolov4.cfg',
    target_classes=['light_post']
)
```

#### MockDetector
Mock detector for testing.

```python
detector = MockDetector(target_classes=['light_post'])
```

## Examples

### Processing Video with GPS

```python
from argus_track import (
    TrackerConfig, 
    LightPostTracker, 
    YOLODetector,
    load_gps_data
)

# Load configuration
config = TrackerConfig.from_yaml('config.yaml')

# Initialize detector
detector = YOLODetector(
    model_path='models/yolov4.weights',
    config_path='models/yolov4.cfg',
    target_classes=['light_post', 'street_light']
)

# Load GPS data
gps_data = load_gps_data('gps_data.csv')

# Initialize tracker
tracker = LightPostTracker(config, detector)

# Process video
tracks = tracker.process_video(
    video_path='street_recording.mp4',
    gps_data=gps_data,
    output_path='tracked_output.mp4'
)

# Analyze results
static_objects = tracker.analyze_static_objects()
print(f"Found {len(static_objects)} static objects")
```

### Custom Detector Integration

```python
from argus_track.detectors import ObjectDetector

class CustomDetector(ObjectDetector):
    def detect(self, frame):
        # Your detection logic here
        return [{
            'bbox': [x1, y1, x2, y2],
            'score': confidence,
            'class_name': 'light_post',
            'class_id': 0
        }]
    
    def get_class_names(self):
        return ['light_post', 'street_light']
```

### Visualization

```python
from bytetrack_lightpost.utils import draw_tracks, plot_track_statistics

# Draw tracks on frame
vis_frame = draw_tracks(frame, active_tracks, show_trajectory=True)

# Plot statistics
plot_track_statistics(all_tracks, save_path='stats.png')
```

## Performance Optimization

### GPU Acceleration

Enable CUDA support for YOLO:

```python
detector = YOLODetector(model_path, config_path)
detector.set_backend('cuda')
```

### Batch Processing

Process multiple videos:

```python
for video_path in video_files:
    tracker.reset()  # Reset tracker state
    tracks = tracker.process_video(video_path)
```

## Development

### Running Tests

```bash
pytest tests/ -v
```

### Code Style

```bash
black argus_track/
flake8 argus_track/
mypy argus_track/
```

### Building Documentation

```bash
cd docs
make html
```

## Contributing

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## License

This project is licensed under the MIT License - see the LICENSE file for details.

## Citation

If you use this code in your research, please cite:

```bibtex
@software{bytetrack_lightpost,
  title={ByteTrack Light Post Tracking System},
  author={Light Post Tracking Team},
  year={2024},
  url={https://github.com/yourusername/bytetrack-lightpost}
}
```

## Acknowledgments

- ByteTrack: [Original Paper](https://arxiv.org/abs/2110.06864)
- FilterPy library for Kalman filtering
- OpenCV for computer vision operations
- The original ByteTrack authors for the innovative tracking algorithm

================
File: setup.py
================
"""
Setup script for ByteTrack Light Post Tracking System
"""

from setuptools import setup, find_packages

with open("README.md", "r", encoding="utf-8") as fh:
    long_description = fh.read()

with open("requirements.txt", "r", encoding="utf-8") as fh:
    requirements = [line.strip() for line in fh if line.strip() and not line.startswith("#")]

setup(
    name="argus-track",
    version="1.0.0",
    author="Light Post Tracking Team",
    author_email="joaquin.olivera@gmail.com",
    description="ByteTrack implementation optimized for light post tracking with GPS integration",
    long_description=long_description,
    long_description_content_type="text/markdown",
    url="https://github.com/Bell-South/ArgusTrack.git",
    packages=find_packages(exclude=["tests", "docs", "examples"]),
    classifiers=[
        "Development Status :: 4 - Beta",
        "Intended Audience :: Developers",
        "Topic :: Scientific/Engineering :: Artificial Intelligence",
        "License :: OSI Approved :: MIT License",
        "Programming Language :: Python :: 3",
        "Programming Language :: Python :: 3.8",
        "Programming Language :: Python :: 3.9",
        "Programming Language :: Python :: 3.10",
    ],
    python_requires=">=3.8",
    install_requires=requirements,
    extras_require={
        "dev": [
            "pytest>=6.0.0",
            "pytest-benchmark>=3.4.0",
            "black>=21.0",
            "flake8>=3.9.0",
            "mypy>=0.910",
        ],
        "docs": [
            "sphinx>=4.0.0",
            "sphinx-rtd-theme>=0.5.0",
        ],
        "gpu": [
            "torch>=1.9.0",
            "torchvision>=0.10.0",
        ],
    },
    entry_points={
        "console_scripts": [
            "argus_track=argus_track.main:main",
        ],
    },
    include_package_data=True,
    package_data={
        "argus_track": ["config/*.yaml", "config/*.json"],
    },
)



================================================================
End of Codebase
================================================================
